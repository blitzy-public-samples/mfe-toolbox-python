{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Methods for Financial Time Series\n",
    "\n",
    "This notebook demonstrates the bootstrap methods available in the MFE Toolbox for financial time series analysis. Bootstrap techniques are essential for statistical inference with dependent data, where standard independence assumptions are often violated.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Bootstrap methods are resampling techniques that allow for statistical inference without making strong distributional assumptions. In financial econometrics, where data often exhibits serial dependence, specialized bootstrap methods are required to preserve the dependence structure.\n",
    "\n",
    "The MFE Toolbox provides several bootstrap methods specifically designed for dependent data:\n",
    "\n",
    "1. **Block Bootstrap**: Resamples blocks of consecutive observations to preserve short-range dependence\n",
    "2. **Stationary Bootstrap**: Uses random block lengths for improved stationarity properties\n",
    "3. **Model Confidence Set (MCS)**: Identifies the set of models that are statistically indistinguishable from the best model\n",
    "4. **Bootstrap Reality Check and SPA Test**: Tests for superior predictive ability among competing forecasting models\n",
    "\n",
    "All bootstrap implementations in the MFE Toolbox leverage NumPy for efficient array operations and Numba for performance acceleration of computationally intensive resampling algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary modules from the MFE Toolbox and other required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any, Callable\n",
    "import asyncio\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# MFE Toolbox imports\n",
    "import mfe\n",
    "from mfe.models.bootstrap import BlockBootstrap, StationaryBootstrap, ModelConfidenceSet, BSDS\n",
    "from mfe.models.univariate import GARCH\n",
    "from mfe.models.distributions import Normal, StudentT\n",
    "from mfe.utils.data_transformations import returns_from_prices\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Display version information\n",
    "print(f\"MFE Toolbox version: {mfe.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Example Data\n",
    "\n",
    "Let's generate some example time series data with known properties to demonstrate bootstrap methods. We'll create an AR(1) process with some volatility clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate an AR(1) process with volatility clustering\n",
    "def generate_ar1_garch11_process(n: int = 1000, ar_coef: float = 0.7, \n",
    "                                omega: float = 0.05, alpha: float = 0.1, beta: float = 0.85) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate an AR(1) process with GARCH(1,1) innovations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of observations\n",
    "    ar_coef : float\n",
    "        AR(1) coefficient\n",
    "    omega : float\n",
    "        GARCH constant term\n",
    "    alpha : float\n",
    "        ARCH parameter\n",
    "    beta : float\n",
    "        GARCH parameter\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Generated time series\n",
    "    \"\"\"\n",
    "    # Initialize arrays\n",
    "    y = np.zeros(n)\n",
    "    sigma2 = np.zeros(n)\n",
    "    sigma2[0] = omega / (1 - alpha - beta)  # Unconditional variance\n",
    "    \n",
    "    # Generate innovations\n",
    "    z = np.random.normal(0, 1, n)\n",
    "    \n",
    "    # Generate process\n",
    "    for t in range(1, n):\n",
    "        # GARCH variance\n",
    "        sigma2[t] = omega + alpha * (z[t-1]**2 * sigma2[t-1]) + beta * sigma2[t-1]\n",
    "        \n",
    "        # AR(1) process with GARCH innovations\n",
    "        y[t] = ar_coef * y[t-1] + np.sqrt(sigma2[t]) * z[t]\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Generate data\n",
    "n_obs = 1000\n",
    "ar_data = generate_ar1_garch11_process(n=n_obs)\n",
    "\n",
    "# Create a date range for our time series\n",
    "dates = pd.date_range(start='2020-01-01', periods=n_obs, freq='B')\n",
    "\n",
    "# Create a Pandas Series with DatetimeIndex\n",
    "ts_data = pd.Series(ar_data, index=dates, name='value')\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ts_data.index, ts_data.values)\n",
    "plt.title('Simulated AR(1) Process with GARCH(1,1) Innovations')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Time Series Summary Statistics:\")\n",
    "print(ts_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check the autocorrelation structure of our simulated data to confirm it has the expected properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check autocorrelation structure\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# ACF of time series\n",
    "plot_acf(ts_data.values, lags=30, ax=axes[0], title='Autocorrelation Function (ACF)')\n",
    "axes[0].set_xlabel('Lag')\n",
    "axes[0].set_ylabel('Autocorrelation')\n",
    "\n",
    "# PACF of time series\n",
    "plot_pacf(ts_data.values, lags=30, ax=axes[1], title='Partial Autocorrelation Function (PACF)')\n",
    "axes[1].set_xlabel('Lag')\n",
    "axes[1].set_ylabel('Partial Autocorrelation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for volatility clustering (autocorrelation in squared returns)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plot_acf(ts_data.values**2, lags=30, title='ACF of Squared Values (Volatility Clustering)')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Block Bootstrap\n",
    "\n",
    "The block bootstrap method resamples blocks of consecutive observations to preserve the dependence structure in the data. This is particularly useful for time series data where observations are not independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a block bootstrap with block size 50\n",
    "block_size = 50\n",
    "block_bootstrap = BlockBootstrap(block_size=block_size)\n",
    "\n",
    "# Generate 1000 bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "bootstrap_samples = block_bootstrap.generate(ts_data.values, num_samples=num_bootstrap_samples)\n",
    "\n",
    "# Compute bootstrap statistics (e.g., mean of each sample)\n",
    "bootstrap_means = np.array([sample.mean() for sample in bootstrap_samples])\n",
    "bootstrap_stds = np.array([sample.std() for sample in bootstrap_samples])\n",
    "\n",
    "# Plot the bootstrap distribution of the mean\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(bootstrap_means, kde=True, stat='density', bins=50)\n",
    "plt.axvline(ts_data.mean(), color='r', linestyle='--', label='Sample Mean')\n",
    "plt.title('Block Bootstrap Distribution of Mean')\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute bootstrap confidence interval for the mean\n",
    "mean_ci = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "print(f\"95% Bootstrap Confidence Interval for Mean: [{mean_ci[0]:.6f}, {mean_ci[1]:.6f}]\")\n",
    "print(f\"Sample Mean: {ts_data.mean():.6f}\")\n",
    "\n",
    "# Plot the bootstrap distribution of the standard deviation\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(bootstrap_stds, kde=True, stat='density', bins=50)\n",
    "plt.axvline(ts_data.std(), color='r', linestyle='--', label='Sample Std Dev')\n",
    "plt.title('Block Bootstrap Distribution of Standard Deviation')\n",
    "plt.xlabel('Standard Deviation')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute bootstrap confidence interval for the standard deviation\n",
    "std_ci = np.percentile(bootstrap_stds, [2.5, 97.5])\n",
    "print(f\"95% Bootstrap Confidence Interval for Std Dev: [{std_ci[0]:.6f}, {std_ci[1]:.6f}]\")\n",
    "print(f\"Sample Std Dev: {ts_data.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Bootstrap Samples\n",
    "\n",
    "Let's visualize a few bootstrap samples to understand how the block bootstrap works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few bootstrap samples\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot original data\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(ts_data.values, label='Original Data')\n",
    "plt.title('Original Time Series')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot two bootstrap samples\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(bootstrap_samples[0], label='Bootstrap Sample 1')\n",
    "plt.title(f'Block Bootstrap Sample 1 (Block Size = {block_size})')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(bootstrap_samples[1], label='Bootstrap Sample 2')\n",
    "plt.title(f'Block Bootstrap Sample 2 (Block Size = {block_size})')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Size Selection\n",
    "\n",
    "The choice of block size is crucial for the block bootstrap. Let's examine how different block sizes affect the bootstrap distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different block sizes\n",
    "block_sizes = [10, 30, 50, 100]\n",
    "bootstrap_means_by_block = {}\n",
    "bootstrap_stds_by_block = {}\n",
    "\n",
    "for bs in block_sizes:\n",
    "    # Create bootstrap with current block size\n",
    "    bootstrap = BlockBootstrap(block_size=bs)\n",
    "    \n",
    "    # Generate bootstrap samples\n",
    "    samples = bootstrap.generate(ts_data.values, num_samples=1000)\n",
    "    \n",
    "    # Compute statistics\n",
    "    bootstrap_means_by_block[bs] = np.array([sample.mean() for sample in samples])\n",
    "    bootstrap_stds_by_block[bs] = np.array([sample.std() for sample in samples])\n",
    "\n",
    "# Plot bootstrap distributions for different block sizes\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot distributions of means\n",
    "plt.subplot(2, 1, 1)\n",
    "for bs in block_sizes:\n",
    "    sns.kdeplot(bootstrap_means_by_block[bs], label=f'Block Size = {bs}')\n",
    "plt.axvline(ts_data.mean(), color='r', linestyle='--', label='Sample Mean')\n",
    "plt.title('Block Bootstrap Distribution of Mean for Different Block Sizes')\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot distributions of standard deviations\n",
    "plt.subplot(2, 1, 2)\n",
    "for bs in block_sizes:\n",
    "    sns.kdeplot(bootstrap_stds_by_block[bs], label=f'Block Size = {bs}')\n",
    "plt.axvline(ts_data.std(), color='r', linestyle='--', label='Sample Std Dev')\n",
    "plt.title('Block Bootstrap Distribution of Standard Deviation for Different Block Sizes')\n",
    "plt.xlabel('Standard Deviation')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute confidence intervals for different block sizes\n",
    "print(\"95% Bootstrap Confidence Intervals for Different Block Sizes:\")\n",
    "print(\"\nMean:\")\n",
    "for bs in block_sizes:\n",
    "    ci = np.percentile(bootstrap_means_by_block[bs], [2.5, 97.5])\n",
    "    width = ci[1] - ci[0]\n",
    "    print(f\"Block Size = {bs}: [{ci[0]:.6f}, {ci[1]:.6f}], Width = {width:.6f}\")\n",
    "\n",
    "print(\"\nStandard Deviation:\")\n",
    "for bs in block_sizes:\n",
    "    ci = np.percentile(bootstrap_stds_by_block[bs], [2.5, 97.5])\n",
    "    width = ci[1] - ci[0]\n",
    "    print(f\"Block Size = {bs}: [{ci[0]:.6f}, {ci[1]:.6f}], Width = {width:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numba-Accelerated Implementation\n",
    "\n",
    "The block bootstrap implementation in the MFE Toolbox uses Numba's just-in-time compilation for performance-critical operations. Let's compare the performance of the Numba-accelerated implementation with a pure Python implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pure Python implementation of block bootstrap\n",
    "def generate_block_bootstrap_indices_python(n: int, block_size: int, seed: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate bootstrap indices without Numba acceleration.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Length of the original series\n",
    "    block_size : int\n",
    "        Size of each block\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array of bootstrap indices\n",
    "    \"\"\"\n",
    "    # Set random seed if provided\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Initialize indices array\n",
    "    indices = np.zeros(n, dtype=np.int64)\n",
    "    \n",
    "    # Generate blocks until we have enough indices\n",
    "    pos = 0\n",
    "    while pos < n:\n",
    "        # Randomly select block start\n",
    "        block_start = np.random.randint(0, n - block_size + 1)\n",
    "        \n",
    "        # Add block indices\n",
    "        block_end = min(pos + block_size, n)\n",
    "        indices[pos:block_end] = np.arange(block_start, block_start + (block_end - pos))\n",
    "        \n",
    "        # Move position\n",
    "        pos = block_end\n",
    "    \n",
    "    return indices\n",
    "\n",
    "def generate_block_bootstrap_python(data: np.ndarray, num_samples: int, block_size: int) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate block bootstrap samples using pure Python implementation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Original data array\n",
    "    num_samples : int\n",
    "        Number of bootstrap samples to generate\n",
    "    block_size : int\n",
    "        Size of each block\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[np.ndarray]\n",
    "        List of bootstrap samples\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    samples = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Generate indices\n",
    "        indices = generate_block_bootstrap_indices_python(n, block_size)\n",
    "        \n",
    "        # Create bootstrap sample\n",
    "        sample = data[indices]\n",
    "        samples.append(sample)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Compare performance\n",
    "block_size = 50\n",
    "num_samples = 100\n",
    "\n",
    "# Time Numba-accelerated version\n",
    "start_time = time.time()\n",
    "block_bootstrap = BlockBootstrap(block_size=block_size)\n",
    "numba_samples = block_bootstrap.generate(ts_data.values, num_samples=num_samples)\n",
    "numba_time = time.time() - start_time\n",
    "\n",
    "# Time Python version\n",
    "start_time = time.time()\n",
    "python_samples = generate_block_bootstrap_python(ts_data.values, num_samples, block_size)\n",
    "python_time = time.time() - start_time\n",
    "\n",
    "print(f\"Numba-accelerated version: {numba_time:.4f} seconds\")\n",
    "print(f\"Python version: {python_time:.4f} seconds\")\n",
    "print(f\"Speedup factor: {python_time / numba_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stationary Bootstrap\n",
    "\n",
    "The stationary bootstrap improves upon the block bootstrap by using random block lengths, which enhances the stationarity properties of the resampled series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stationary bootstrap with expected block size 50\n",
    "expected_block_size = 50\n",
    "stationary_bootstrap = StationaryBootstrap(expected_block_size=expected_block_size)\n",
    "\n",
    "# Generate 1000 bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "stat_bootstrap_samples = stationary_bootstrap.generate(ts_data.values, num_samples=num_bootstrap_samples)\n",
    "\n",
    "# Compute bootstrap statistics\n",
    "stat_bootstrap_means = np.array([sample.mean() for sample in stat_bootstrap_samples])\n",
    "stat_bootstrap_stds = np.array([sample.std() for sample in stat_bootstrap_samples])\n",
    "\n",
    "# Plot the bootstrap distribution of the mean\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(stat_bootstrap_means, kde=True, stat='density', bins=50)\n",
    "plt.axvline(ts_data.mean(), color='r', linestyle='--', label='Sample Mean')\n",
    "plt.title('Stationary Bootstrap Distribution of Mean')\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute bootstrap confidence interval for the mean\n",
    "stat_mean_ci = np.percentile(stat_bootstrap_means, [2.5, 97.5])\n",
    "print(f\"95% Bootstrap Confidence Interval for Mean: [{stat_mean_ci[0]:.6f}, {stat_mean_ci[1]:.6f}]\")\n",
    "print(f\"Sample Mean: {ts_data.mean():.6f}\")\n",
    "\n",
    "# Plot the bootstrap distribution of the standard deviation\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(stat_bootstrap_stds, kde=True, stat='density', bins=50)\n",
    "plt.axvline(ts_data.std(), color='r', linestyle='--', label='Sample Std Dev')\n",
    "plt.title('Stationary Bootstrap Distribution of Standard Deviation')\n",
    "plt.xlabel('Standard Deviation')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute bootstrap confidence interval for the standard deviation\n",
    "stat_std_ci = np.percentile(stat_bootstrap_stds, [2.5, 97.5])\n",
    "print(f\"95% Bootstrap Confidence Interval for Std Dev: [{stat_std_ci[0]:.6f}, {stat_std_ci[1]:.6f}]\")\n",
    "print(f\"Sample Std Dev: {ts_data.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Block and Stationary Bootstrap\n",
    "\n",
    "Let's compare the distributions of statistics from the block bootstrap and stationary bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions of means\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.kdeplot(bootstrap_means, label='Block Bootstrap')\n",
    "sns.kdeplot(stat_bootstrap_means, label='Stationary Bootstrap')\n",
    "plt.axvline(ts_data.mean(), color='r', linestyle='--', label='Sample Mean')\n",
    "plt.title('Comparison of Bootstrap Distributions of Mean')\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare distributions of standard deviations\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.kdeplot(bootstrap_stds, label='Block Bootstrap')\n",
    "sns.kdeplot(stat_bootstrap_stds, label='Stationary Bootstrap')\n",
    "plt.axvline(ts_data.std(), color='r', linestyle='--', label='Sample Std Dev')\n",
    "plt.title('Comparison of Bootstrap Distributions of Standard Deviation')\n",
    "plt.xlabel('Standard Deviation')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare confidence intervals\n",
    "print(\"95% Bootstrap Confidence Intervals:\")\n",
    "print(f\"Block Bootstrap Mean: [{mean_ci[0]:.6f}, {mean_ci[1]:.6f}], Width = {mean_ci[1] - mean_ci[0]:.6f}\")\n",
    "print(f\"Stationary Bootstrap Mean: [{stat_mean_ci[0]:.6f}, {stat_mean_ci[1]:.6f}], Width = {stat_mean_ci[1] - stat_mean_ci[0]:.6f}\")\n",
    "print(f\"\nBlock Bootstrap Std Dev: [{std_ci[0]:.6f}, {std_ci[1]:.6f}], Width = {std_ci[1] - std_ci[0]:.6f}\")\n",
    "print(f\"Stationary Bootstrap Std Dev: [{stat_std_ci[0]:.6f}, {stat_std_ci[1]:.6f}], Width = {stat_std_ci[1] - stat_std_ci[0]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Processing with Progress Tracking\n",
    "\n",
    "For large-scale bootstrap operations, the MFE Toolbox provides asynchronous processing with progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a progress callback function\n",
    "def progress_callback(percent: float, message: str) -> None:\n",
    "    \"\"\"\n",
    "    Callback function to report progress.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    percent : float\n",
    "        Percentage of completion (0-100)\n",
    "    message : str\n",
    "        Progress message\n",
    "    \"\"\"\n",
    "    print(f\"{percent:.1f}% complete: {message}\")\n",
    "\n",
    "# Define an asynchronous function to run bootstrap\n",
    "async def run_bootstrap_async() -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Run bootstrap asynchronously with progress tracking.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        Lower and upper bounds of confidence interval\n",
    "    \"\"\"\n",
    "    # Create a stationary bootstrap\n",
    "    bootstrap = StationaryBootstrap(expected_block_size=50)\n",
    "    \n",
    "    # Generate 5,000 bootstrap samples asynchronously with progress tracking\n",
    "    print(\"Generating 5,000 bootstrap samples asynchronously...\")\n",
    "    bootstrap_samples = await bootstrap.generate_async(\n",
    "        ts_data.values, \n",
    "        num_samples=5000,\n",
    "        progress_callback=progress_callback\n",
    "    )\n",
    "    \n",
    "    # Compute bootstrap statistics\n",
    "    bootstrap_means = np.array([sample.mean() for sample in bootstrap_samples])\n",
    "    conf_interval = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "    \n",
    "    return conf_interval[0], conf_interval[1]\n",
    "\n",
    "# Run the async function\n",
    "lower_bound, upper_bound = await run_bootstrap_async()\n",
    "print(f\"\n95% Bootstrap Confidence Interval: [{lower_bound:.6f}, {upper_bound:.6f}]\")\n",
    "print(f\"Sample Mean: {ts_data.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bootstrap for Parameter Uncertainty in GARCH Models\n",
    "\n",
    "Let's use bootstrap methods to assess parameter uncertainty in GARCH models. We'll first estimate a GARCH model, then use bootstrap to construct confidence intervals for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate financial returns data with GARCH effects\n",
    "def generate_garch_returns(n: int = 1000, \n",
    "                          omega: float = 0.05, \n",
    "                          alpha: float = 0.1, \n",
    "                          beta: float = 0.85) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate returns from a GARCH(1,1) process.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of observations\n",
    "    omega : float\n",
    "        GARCH constant term\n",
    "    alpha : float\n",
    "        ARCH parameter\n",
    "    beta : float\n",
    "        GARCH parameter\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Generated returns\n",
    "    \"\"\"\n",
    "    # Initialize arrays\n",
    "    returns = np.zeros(n)\n",
    "    sigma2 = np.zeros(n)\n",
    "    sigma2[0] = omega / (1 - alpha - beta)  # Unconditional variance\n",
    "    \n",
    "    # Generate innovations\n",
    "    z = np.random.normal(0, 1, n)\n",
    "    \n",
    "    # Generate process\n",
    "    for t in range(1, n):\n",
    "        # GARCH variance\n",
    "        sigma2[t] = omega + alpha * returns[t-1]**2 + beta * sigma2[t-1]\n",
    "        \n",
    "        # Returns\n",
    "        returns[t] = np.sqrt(sigma2[t]) * z[t]\n",
    "    \n",
    "    return returns\n",
    "\n",
    "# Generate returns data\n",
    "np.random.seed(42)\n",
    "n_obs = 1000\n",
    "true_omega = 0.05\n",
    "true_alpha = 0.1\n",
    "true_beta = 0.85\n",
    "returns_data = generate_garch_returns(n=n_obs, omega=true_omega, alpha=true_alpha, beta=true_beta)\n",
    "\n",
    "# Create a date range for our returns\n",
    "dates = pd.date_range(start='2020-01-01', periods=n_obs, freq='B')\n",
    "\n",
    "# Create a Pandas Series with DatetimeIndex\n",
    "returns_series = pd.Series(returns_data, index=dates, name='returns')\n",
    "\n",
    "# Plot the returns\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(returns_series.index, returns_series.values)\n",
    "plt.title('Simulated GARCH(1,1) Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Returns')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estimate GARCH(1,1) model\n",
    "garch_model = GARCH(p=1, q=1, distribution=Normal())\n",
    "garch_results = garch_model.fit(returns_data)\n",
    "\n",
    "# Display estimation results\n",
    "print(\"GARCH(1,1) Estimation Results:\")\n",
    "print(f\"Log-Likelihood: {garch_results.log_likelihood:.4f}\")\n",
    "print(f\"AIC: {garch_results.aic:.4f}\")\n",
    "print(f\"BIC: {garch_results.bic:.4f}\")\n",
    "print(\"\nParameter Estimates:\")\n",
    "for name, value, std_err, t_stat, p_value in zip(\n",
    "    garch_results.parameter_names,\n",
    "    garch_results.parameters,\n",
    "    garch_results.std_errors,\n",
    "    garch_results.t_stats,\n",
    "    garch_results.p_values\n",
    "):\n",
    "    print(f\"{name}: {value:.6f} (SE: {std_err:.6f}, t: {t_stat:.4f}, p: {p_value:.4f})\")\n",
    "\n",
    "# Compare with true parameters\n",
    "print(\"\nTrue Parameters:\")\n",
    "print(f\"omega: {true_omega:.6f}\")\n",
    "print(f\"alpha: {true_alpha:.6f}\")\n",
    "print(f\"beta: {true_beta:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric Bootstrap for GARCH Models\n",
    "\n",
    "Now let's use parametric bootstrap to assess parameter uncertainty. We'll simulate data from the estimated model, re-estimate the model on each simulated dataset, and construct confidence intervals for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametric bootstrap for GARCH models\n",
    "def parametric_bootstrap_garch(returns: np.ndarray, model: GARCH, \n",
    "                              estimated_params: np.ndarray, \n",
    "                              num_bootstrap: int = 1000) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform parametric bootstrap for GARCH models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : np.ndarray\n",
    "        Original returns data\n",
    "    model : GARCH\n",
    "        Estimated GARCH model\n",
    "    estimated_params : np.ndarray\n",
    "        Estimated parameters\n",
    "    num_bootstrap : int, optional\n",
    "        Number of bootstrap replications\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, np.ndarray]\n",
    "        Dictionary of bootstrap parameter distributions\n",
    "    \"\"\"\n",
    "    # Get parameter names\n",
    "    param_names = model.parameter_names\n",
    "    \n",
    "    # Initialize arrays to store bootstrap parameters\n",
    "    bootstrap_params = {name: np.zeros(num_bootstrap) for name in param_names}\n",
    "    \n",
    "    # Perform bootstrap replications\n",
    "    for i in range(num_bootstrap):\n",
    "        # Progress update\n",
    "        if (i + 1) % 100 == 0 or i == 0:\n",
    "            print(f\"Bootstrap replication {i + 1}/{num_bootstrap}\")\n",
    "        \n",
    "        # Simulate data from the estimated model\n",
    "        sim_result = model.simulate(\n",
    "            estimated_params,\n",
    "            len(returns),\n",
    "            n_simulations=1,\n",
    "            initial_value=returns[0],\n",
    "            initial_variance=np.var(returns)\n",
    "        )\n",
    "        sim_returns = sim_result.returns[:, 0]  # Get the first (and only) simulation\n",
    "        \n",
    "        try:\n",
    "            # Re-estimate the model on simulated data\n",
    "            bootstrap_result = model.fit(sim_returns)\n",
    "            \n",
    "            # Store parameters\n",
    "            for j, name in enumerate(param_names):\n",
    "                bootstrap_params[name][i] = bootstrap_result.parameters[j]\n",
    "        except Exception as e:\n",
    "            # If estimation fails, use original parameters\n",
    "            print(f\"Warning: Estimation failed for bootstrap sample {i + 1}: {e}\")\n",
    "            for j, name in enumerate(param_names):\n",
    "                bootstrap_params[name][i] = estimated_params[j]\n",
    "    \n",
    "    return bootstrap_params\n",
    "\n",
    "# Run parametric bootstrap (with fewer replications for demonstration)\n",
    "num_bootstrap = 200  # Use a smaller number for demonstration\n",
    "bootstrap_params = parametric_bootstrap_garch(\n",
    "    returns_data, garch_model, garch_results.parameters, num_bootstrap=num_bootstrap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bootstrap distributions of parameters\n",
    "param_names = garch_model.parameter_names\n",
    "fig, axes = plt.subplots(len(param_names), 1, figsize=(14, 4 * len(param_names)))\n",
    "\n",
    "for i, name in enumerate(param_names):\n",
    "    # Get true parameter value if available\n",
    "    true_value = None\n",
    "    if name == 'omega':\n",
    "        true_value = true_omega\n",
    "    elif name == 'alpha[1]':\n",
    "        true_value = true_alpha\n",
    "    elif name == 'beta[1]':\n",
    "        true_value = true_beta\n",
    "    \n",
    "    # Plot bootstrap distribution\n",
    "    sns.histplot(bootstrap_params[name], kde=True, ax=axes[i])\n",
    "    \n",
    "    # Add vertical lines for estimated and true values\n",
    "    axes[i].axvline(garch_results.parameters[i], color='r', linestyle='--', \n",
    "                   label=f'Estimated: {garch_results.parameters[i]:.6f}')\n",
    "    \n",
    "    if true_value is not None:\n",
    "        axes[i].axvline(true_value, color='g', linestyle='-', \n",
    "                       label=f'True: {true_value:.6f}')\n",
    "    \n",
    "    # Compute bootstrap confidence interval\n",
    "    ci = np.percentile(bootstrap_params[name], [2.5, 97.5])\n",
    "    axes[i].axvline(ci[0], color='b', linestyle=':', label=f'2.5%: {ci[0]:.6f}')\n",
    "    axes[i].axvline(ci[1], color='b', linestyle=':', label=f'97.5%: {ci[1]:.6f}')\n",
    "    \n",
    "    axes[i].set_title(f'Bootstrap Distribution of {name}')\n",
    "    axes[i].set_xlabel(f'{name}')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print bootstrap confidence intervals\n",
    "print(\"95% Bootstrap Confidence Intervals:\")\n",
    "for name in param_names:\n",
    "    ci = np.percentile(bootstrap_params[name], [2.5, 97.5])\n",
    "    print(f\"{name}: [{ci[0]:.6f}, {ci[1]:.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Bootstrap for GARCH Models\n",
    "\n",
    "Now let's use residual bootstrap as an alternative approach. We'll resample the standardized residuals from the estimated model, generate new returns series, and re-estimate the model on each bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual bootstrap for GARCH models\n",
    "def residual_bootstrap_garch(returns: np.ndarray, model: GARCH, \n",
    "                            estimated_params: np.ndarray, \n",
    "                            std_residuals: np.ndarray,\n",
    "                            num_bootstrap: int = 1000) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform residual bootstrap for GARCH models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : np.ndarray\n",
    "        Original returns data\n",
    "    model : GARCH\n",
    "        Estimated GARCH model\n",
    "    estimated_params : np.ndarray\n",
    "        Estimated parameters\n",
    "    std_residuals : np.ndarray\n",
    "        Standardized residuals from the estimated model\n",
    "    num_bootstrap : int, optional\n",
    "        Number of bootstrap replications\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, np.ndarray]\n",
    "        Dictionary of bootstrap parameter distributions\n",
    "    \"\"\"\n",
    "    # Get parameter names\n",
    "    param_names = model.parameter_names\n",
    "    \n",
    "    # Initialize arrays to store bootstrap parameters\n",
    "    bootstrap_params = {name: np.zeros(num_bootstrap) for name in param_names}\n",
    "    \n",
    "    # Extract GARCH parameters\n",
    "    omega = estimated_params[0]\n",
    "    alpha = estimated_params[1]\n",
    "    beta = estimated_params[2]\n",
    "    \n",
    "    # Number of observations\n",
    "    n = len(returns)\n",
    "    \n",
    "    # Perform bootstrap replications\n",
    "    for i in range(num_bootstrap):\n",
    "        # Progress update\n",
    "        if (i + 1) % 100 == 0 or i == 0:\n",
    "            print(f\"Bootstrap replication {i + 1}/{num_bootstrap}\")\n",
    "        \n",
    "        # Resample standardized residuals\n",
    "        bootstrap_indices = np.random.choice(n, size=n, replace=True)\n",
    "        bootstrap_residuals = std_residuals[bootstrap_indices]\n",
    "        \n",
    "        # Generate bootstrap returns\n",
    "        bootstrap_returns = np.zeros(n)\n",
    "        bootstrap_sigma2 = np.zeros(n)\n",
    "        bootstrap_sigma2[0] = np.var(returns)  # Initial variance\n",
    "        \n",
    "        for t in range(1, n):\n",
    "            # GARCH variance\n",
    "            bootstrap_sigma2[t] = omega + alpha * bootstrap_returns[t-1]**2 + beta * bootstrap_sigma2[t-1]\n",
    "            \n",
    "            # Returns\n",
    "            bootstrap_returns[t] = np.sqrt(bootstrap_sigma2[t]) * bootstrap_residuals[t]\n",
    "        \n",
    "        try:\n",
    "            # Re-estimate the model on bootstrap data\n",
    "            bootstrap_result = model.fit(bootstrap_returns)\n",
    "            \n",
    "            # Store parameters\n",
    "            for j, name in enumerate(param_names):\n",
    "                bootstrap_params[name][i] = bootstrap_result.parameters[j]\n",
    "        except Exception as e:\n",
    "            # If estimation fails, use original parameters\n",
    "            print(f\"Warning: Estimation failed for bootstrap sample {i + 1}: {e}\")\n",
    "            for j, name in enumerate(param_names):\n",
    "                bootstrap_params[name][i] = estimated_params[j]\n",
    "    \n",
    "    return bootstrap_params\n",
    "\n",
    "# Get standardized residuals from the estimated model\n",
    "std_residuals = garch_results.standardized_residuals\n",
    "\n",
    "# Run residual bootstrap (with fewer replications for demonstration)\n",
    "num_bootstrap = 200  # Use a smaller number for demonstration\n",
    "residual_bootstrap_params = residual_bootstrap_garch(\n",
    "    returns_data, garch_model, garch_results.parameters, std_residuals, num_bootstrap=num_bootstrap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare parametric and residual bootstrap distributions\n",
    "param_names = garch_model.parameter_names\n",
    "fig, axes = plt.subplots(len(param_names), 1, figsize=(14, 4 * len(param_names)))\n",
    "\n",
    "for i, name in enumerate(param_names):\n",
    "    # Plot bootstrap distributions\n",
    "    sns.kdeplot(bootstrap_params[name], ax=axes[i], label='Parametric Bootstrap')\n",
    "    sns.kdeplot(residual_bootstrap_params[name], ax=axes[i], label='Residual Bootstrap')\n",
    "    \n",
    "    # Add vertical line for estimated value\n",
    "    axes[i].axvline(garch_results.parameters[i], color='r', linestyle='--', \n",
    "                   label=f'Estimated: {garch_results.parameters[i]:.6f}')\n",
    "    \n",
    "    # Add vertical line for true value if available\n",
    "    true_value = None\n",
    "    if name == 'omega':\n",
    "        true_value = true_omega\n",
    "    elif name == 'alpha[1]':\n",
    "        true_value = true_alpha\n",
    "    elif name == 'beta[1]':\n",
    "        true_value = true_beta\n",
    "    \n",
    "    if true_value is not None:\n",
    "        axes[i].axvline(true_value, color='g', linestyle='-', \n",
    "                       label=f'True: {true_value:.6f}')\n",
    "    \n",
    "    axes[i].set_title(f'Bootstrap Distributions of {name}')\n",
    "    axes[i].set_xlabel(f'{name}')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print and compare bootstrap confidence intervals\n",
    "print(\"95% Bootstrap Confidence Intervals:\")\n",
    "for name in param_names:\n",
    "    param_ci = np.percentile(bootstrap_params[name], [2.5, 97.5])\n",
    "    resid_ci = np.percentile(residual_bootstrap_params[name], [2.5, 97.5])\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Parametric: [{param_ci[0]:.6f}, {param_ci[1]:.6f}], Width = {param_ci[1] - param_ci[0]:.6f}\")\n",
    "    print(f\"  Residual:   [{resid_ci[0]:.6f}, {resid_ci[1]:.6f}], Width = {resid_ci[1] - resid_ci[0]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Confidence Set (MCS)\n",
    "\n",
    "The Model Confidence Set (MCS) procedure identifies the set of models that are statistically indistinguishable from the best model based on a user-defined loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate loss data for 5 different models over 100 time periods\n",
    "np.random.seed(42)\n",
    "n_models = 5\n",
    "n_periods = 100\n",
    "\n",
    "# Model 0 and 1 are the best, others are worse\n",
    "base_losses = np.random.normal(0, 1, (n_periods, n_models))\n",
    "base_losses[:, 2:] += 0.5  # Models 2-4 have higher loss\n",
    "\n",
    "# Create model names\n",
    "model_names = [f\"Model {i+1}\" for i in range(n_models)]\n",
    "\n",
    "# Create a Model Confidence Set\n",
    "mcs = ModelConfidenceSet(\n",
    "    block_size=10,           # Block size for bootstrap\n",
    "    num_bootstrap=1000,      # Number of bootstrap replications\n",
    "    significance_level=0.05  # Significance level\n",
    ")\n",
    "\n",
    "# Run the MCS procedure\n",
    "mcs_result = mcs.run(base_losses, model_names=model_names)\n",
    "\n",
    "# Print results\n",
    "print(\"Model Confidence Set Results:\")\n",
    "print(f\"Included models: {[model_names[i] for i in mcs_result.included_models]}\")\n",
    "print(f\"Excluded models: {[model_names[i] for i in mcs_result.excluded_models]}\")\n",
    "print(\"\nModel p-values:\")\n",
    "for i, p_val in enumerate(mcs_result.pvalues):\n",
    "    print(f\"{model_names[i]}: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MCS results\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(model_names, mcs_result.pvalues)\n",
    "\n",
    "# Color bars based on inclusion in MCS\n",
    "for i, model_idx in enumerate(range(n_models)):\n",
    "    if model_idx in mcs_result.included_models:\n",
    "        bars[i].set_color('green')\n",
    "    else:\n",
    "        bars[i].set_color('red')\n",
    "\n",
    "plt.axhline(mcs.significance_level, color='black', linestyle='--', \n",
    "            label=f'Significance Level ({mcs.significance_level})')\n",
    "plt.title('Model Confidence Set p-values')\n",
    "plt.ylabel('p-value')\n",
    "plt.xlabel('Model')\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCS with Different Bootstrap Methods\n",
    "\n",
    "Let's compare the results of the MCS procedure using different bootstrap methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MCS with block bootstrap\n",
    "mcs_block = ModelConfidenceSet(\n",
    "    block_size=10,\n",
    "    num_bootstrap=1000,\n",
    "    significance_level=0.05,\n",
    "    bootstrap_method='block'  # Explicitly specify block bootstrap\n",
    ")\n",
    "mcs_block_result = mcs_block.run(base_losses, model_names=model_names)\n",
    "\n",
    "# Run MCS with stationary bootstrap\n",
    "mcs_stationary = ModelConfidenceSet(\n",
    "    block_size=10,  # Used as expected block size for stationary bootstrap\n",
    "    num_bootstrap=1000,\n",
    "    significance_level=0.05,\n",
    "    bootstrap_method='stationary'  # Specify stationary bootstrap\n",
    ")\n",
    "mcs_stationary_result = mcs_stationary.run(base_losses, model_names=model_names)\n",
    "\n",
    "# Compare results\n",
    "print(\"MCS Results with Block Bootstrap:\")\n",
    "print(f\"Included models: {[model_names[i] for i in mcs_block_result.included_models]}\")\n",
    "print(\"\nMCS Results with Stationary Bootstrap:\")\n",
    "print(f\"Included models: {[model_names[i] for i in mcs_stationary_result.included_models]}\")\n",
    "\n",
    "# Compare p-values\n",
    "print(\"\nModel p-values:\")\n",
    "for i in range(n_models):\n",
    "    print(f\"{model_names[i]}: Block = {mcs_block_result.pvalues[i]:.4f}, Stationary = {mcs_stationary_result.pvalues[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison of p-values\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, mcs_block_result.pvalues, width, label='Block Bootstrap')\n",
    "plt.bar(x + width/2, mcs_stationary_result.pvalues, width, label='Stationary Bootstrap')\n",
    "\n",
    "plt.axhline(0.05, color='black', linestyle='--', label='Significance Level (0.05)')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('p-value')\n",
    "plt.title('Comparison of MCS p-values with Different Bootstrap Methods')\n",
    "plt.xticks(x, model_names)\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bootstrap Reality Check and SPA Test\n",
    "\n",
    "The Bootstrap Reality Check (BRC) and Superior Predictive Ability (SPA) tests evaluate whether any model in a set outperforms a benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate loss data for benchmark and 5 competing models\n",
    "np.random.seed(42)\n",
    "n_periods = 100\n",
    "n_models = 5\n",
    "\n",
    "# Benchmark model losses\n",
    "benchmark_losses = np.random.normal(0, 1, n_periods)\n",
    "\n",
    "# Competing models' losses (model 0 is better, others are not)\n",
    "model_losses = np.random.normal(0, 1, (n_periods, n_models))\n",
    "model_losses[:, 0] -= 0.3  # Model 0 has lower loss\n",
    "\n",
    "# Create model names\n",
    "model_names = [f\"Model {i+1}\" for i in range(n_models)]\n",
    "\n",
    "# Create a BSDS test\n",
    "bsds = BSDS(\n",
    "    block_size=10,           # Block size for bootstrap\n",
    "    num_bootstrap=1000,      # Number of bootstrap replications\n",
    "    seed=42                  # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Run the test\n",
    "bsds_result = bsds.run(benchmark_losses, model_losses, model_names=model_names)\n",
    "\n",
    "# Print results\n",
    "print(\"BSDS Test Results:\")\n",
    "print(f\"Reality Check p-value: {bsds_result.rc_pvalue:.4f}\")\n",
    "print(f\"SPA p-value: {bsds_result.spa_pvalue:.4f}\")\n",
    "print(\"\nIndividual model p-values:\")\n",
    "for i, p_val in enumerate(bsds_result.model_pvalues):\n",
    "    print(f\"{model_names[i]}: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize BSDS results\n",
    "# Calculate loss differences\n",
    "loss_diffs = np.mean(benchmark_losses.reshape(-1, 1) - model_losses, axis=0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(model_names, loss_diffs)\n",
    "\n",
    "# Color bars based on significance\n",
    "for i, p_val in enumerate(bsds_result.model_pvalues):\n",
    "    if p_val < 0.05:\n",
    "        bars[i].set_color('green')\n",
    "    else:\n",
    "        bars[i].set_color('red')\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', label='Benchmark')\n",
    "plt.title('Average Loss Difference vs Benchmark')\n",
    "plt.ylabel('Benchmark Loss - Model Loss')\n",
    "plt.xlabel('Model')\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot p-values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(model_names, bsds_result.model_pvalues)\n",
    "plt.axhline(0.05, color='red', linestyle='--', label='Significance Level (0.05)')\n",
    "plt.title('Individual Model p-values')\n",
    "plt.ylabel('p-value')\n",
    "plt.xlabel('Model')\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Bootstrap Functions\n",
    "\n",
    "The MFE Toolbox allows you to create custom bootstrap functions for specialized applications. Let's implement a bootstrap function for Sharpe ratio confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sharpe_ratio(returns: np.ndarray, block_size: int = 20, \n",
    "                          num_samples: int = 1000) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence interval for Sharpe ratio.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : np.ndarray\n",
    "        Array of return data\n",
    "    block_size : int, optional\n",
    "        Size of bootstrap blocks\n",
    "    num_samples : int, optional\n",
    "        Number of bootstrap samples\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float, float]\n",
    "        Tuple containing (sharpe_ratio, lower_bound, upper_bound)\n",
    "    \"\"\"\n",
    "    # Calculate sample Sharpe ratio\n",
    "    sample_sharpe = returns.mean() / returns.std()\n",
    "    \n",
    "    # Create bootstrap\n",
    "    bootstrap = BlockBootstrap(block_size=block_size)\n",
    "    bootstrap_samples = bootstrap.generate(returns, num_samples=num_samples)\n",
    "    \n",
    "    # Compute Sharpe ratio for each bootstrap sample\n",
    "    bootstrap_sharpes = np.array([\n",
    "        sample.mean() / sample.std() for sample in bootstrap_samples\n",
    "    ])\n",
    "    \n",
    "    # Compute confidence interval\n",
    "    conf_interval = np.percentile(bootstrap_sharpes, [2.5, 97.5])\n",
    "    \n",
    "    return sample_sharpe, conf_interval[0], conf_interval[1]\n",
    "\n",
    "# Generate some return data\n",
    "np.random.seed(42)\n",
    "returns = np.random.normal(0.001, 0.01, 1000)  # Daily returns with 0.1% mean and 1% volatility\n",
    "\n",
    "# Compute Sharpe ratio and confidence interval\n",
    "sharpe, lower, upper = bootstrap_sharpe_ratio(returns)\n",
    "print(f\"Sharpe Ratio: {sharpe:.4f}\")\n",
    "print(f\"95% Confidence Interval: [{lower:.4f}, {upper:.4f}]\")\n",
    "\n",
    "# Plot bootstrap distribution of Sharpe ratio\n",
    "bootstrap = BlockBootstrap(block_size=20)\n",
    "bootstrap_samples = bootstrap.generate(returns, num_samples=1000)\n",
    "bootstrap_sharpes = np.array([sample.mean() / sample.std() for sample in bootstrap_samples])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(bootstrap_sharpes, kde=True, bins=50)\n",
    "plt.axvline(sharpe, color='r', linestyle='--', label=f'Sample Sharpe: {sharpe:.4f}')\n",
    "plt.axvline(lower, color='b', linestyle=':', label=f'2.5%: {lower:.4f}')\n",
    "plt.axvline(upper, color='b', linestyle=':', label=f'97.5%: {upper:.4f}')\n",
    "plt.title('Bootstrap Distribution of Sharpe Ratio')\n",
    "plt.xlabel('Sharpe Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Considerations\n",
    "\n",
    "The bootstrap methods in the MFE Toolbox are optimized for performance using Numba's just-in-time compilation. Here are some considerations for optimal performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure performance for different data sizes\n",
    "data_sizes = [1000, 5000, 10000]\n",
    "block_size = 50\n",
    "num_samples = 100\n",
    "\n",
    "print(\"Performance for Different Data Sizes:\")\n",
    "for size in data_sizes:\n",
    "    # Generate data\n",
    "    data = np.random.normal(0, 1, size)\n",
    "    \n",
    "    # Time Numba-accelerated version\n",
    "    bootstrap = BlockBootstrap(block_size=block_size)\n",
    "    start_time = time.time()\n",
    "    _ = bootstrap.generate(data, num_samples=num_samples)\n",
    "    numba_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Data size = {size}: {numba_time:.4f} seconds for {num_samples} bootstrap samples\")\n",
    "\n",
    "# Measure performance for different numbers of bootstrap samples\n",
    "data_size = 1000\n",
    "block_size = 50\n",
    "sample_sizes = [100, 500, 1000]\n",
    "\n",
    "print(\"\nPerformance for Different Numbers of Bootstrap Samples:\")\n",
    "for num_samples in sample_sizes:\n",
    "    # Generate data\n",
    "    data = np.random.normal(0, 1, data_size)\n",
    "    \n",
    "    # Time Numba-accelerated version\n",
    "    bootstrap = BlockBootstrap(block_size=block_size)\n",
    "    start_time = time.time()\n",
    "    _ = bootstrap.generate(data, num_samples=num_samples)\n",
    "    numba_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Number of samples = {num_samples}: {numba_time:.4f} seconds for data size {data_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Processing for Large Datasets\n",
    "\n",
    "For large datasets or many bootstrap samples, asynchronous processing can significantly improve responsiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an asynchronous function to run bootstrap with progress tracking\n",
    "async def run_large_bootstrap_async() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Run bootstrap on a large dataset asynchronously with progress tracking.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Bootstrap statistics\n",
    "    \"\"\"\n",
    "    # Generate a large dataset\n",
    "    np.random.seed(42)\n",
    "    data_size = 10000\n",
    "    data = np.random.normal(0, 1, data_size)\n",
    "    \n",
    "    # Create a bootstrap object\n",
    "    bootstrap = BlockBootstrap(block_size=50)\n",
    "    \n",
    "    # Define a progress callback function\n",
    "    def progress_callback(percent: float, message: str) -> None:\n",
    "        print(f\"{percent:.1f}% complete: {message}\")\n",
    "    \n",
    "    # Generate bootstrap samples asynchronously with progress tracking\n",
    "    print(f\"Generating 1,000 bootstrap samples for data size {data_size}...\")\n",
    "    bootstrap_samples = await bootstrap.generate_async(\n",
    "        data, \n",
    "        num_samples=1000,\n",
    "        progress_callback=progress_callback\n",
    "    )\n",
    "    \n",
    "    # Compute bootstrap statistics\n",
    "    bootstrap_means = np.array([sample.mean() for sample in bootstrap_samples])\n",
    "    \n",
    "    return bootstrap_means\n",
    "\n",
    "# Run the async function\n",
    "bootstrap_means = await run_large_bootstrap_async()\n",
    "\n",
    "# Plot the bootstrap distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(bootstrap_means, kde=True, bins=50)\n",
    "plt.axvline(bootstrap_means.mean(), color='r', linestyle='--', label=f'Mean: {bootstrap_means.mean():.4f}')\n",
    "plt.title('Bootstrap Distribution of Mean for Large Dataset')\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've explored the bootstrap methods available in the MFE Toolbox for financial time series analysis. We've covered:\n",
    "\n",
    "1. **Block Bootstrap**: Resampling blocks of consecutive observations to preserve short-range dependence\n",
    "2. **Stationary Bootstrap**: Using random block lengths for improved stationarity properties\n",
    "3. **Bootstrap for Parameter Uncertainty**: Assessing uncertainty in GARCH model parameters\n",
    "4. **Model Confidence Set (MCS)**: Identifying the set of models that are statistically indistinguishable from the best model\n",
    "5. **Bootstrap Reality Check and SPA Test**: Testing for superior predictive ability among competing forecasting models\n",
    "6. **Custom Bootstrap Functions**: Creating specialized bootstrap applications\n",
    "7. **Performance Considerations**: Optimizing bootstrap methods for large datasets\n",
    "\n",
    "The bootstrap methods in the MFE Toolbox provide powerful tools for statistical inference with dependent data. By leveraging NumPy's efficient array operations and Numba's performance acceleration, these methods enable robust analysis of financial time series data.\n",
    "\n",
    "The implementation in Python with Numba acceleration offers significant advantages over the previous MATLAB implementation, including improved performance, better integration with the Python ecosystem, and support for asynchronous processing with progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display version information\n",
    "print(f\"MFE Toolbox version: {mfe.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
