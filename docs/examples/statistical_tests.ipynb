{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests for Financial Time Series\n",
    "\n",
    "This notebook demonstrates the use of statistical tests in the MFE Toolbox for analyzing financial time series data. Statistical tests are essential for validating model assumptions, checking distribution properties, and detecting patterns in financial data.\n",
    "\n",
    "The MFE Toolbox provides a comprehensive set of statistical tests implemented in Python with integration to NumPy, SciPy, and Pandas. Performance-critical calculations are accelerated using Numba's just-in-time compilation through `@jit` decorators.\n",
    "\n",
    "In this notebook, we'll cover:\n",
    "\n",
    "1. **Normality Tests**: Testing if data follows a normal distribution\n",
    "2. **Distribution Tests**: Testing if data follows specific distributions\n",
    "3. **Serial Correlation Tests**: Testing for autocorrelation in time series\n",
    "4. **ARCH Effect Tests**: Testing for conditional heteroskedasticity\n",
    "5. **Property-Based Testing**: Advanced testing techniques for distribution properties\n",
    "6. **Asynchronous Testing**: Using async/await for non-blocking test execution\n",
    "\n",
    "Let's start by importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import asyncio\n",
    "\n",
    "# Import MFE Toolbox components\n",
    "from mfe.models.tests import (\n",
    "    jarque_bera, jarque_bera_async,\n",
    "    kolmogorov_smirnov, kolmogorov_smirnov_async,\n",
    "    berkowitz, berkowitz_async,\n",
    "    ljung_box, ljung_box_async,\n",
    "    lm_test, lm_test_async,\n",
    "    pvalue_calculator\n",
    ")\n",
    "\n",
    "# Import models for generating test data\n",
    "from mfe import GARCH, ARMA\n",
    "\n",
    "# Import distributions\n",
    "from mfe.models.distributions import normal, student_t, generalized_error, skewed_t\n",
    "\n",
    "# Set up plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Test Data\n",
    "\n",
    "Let's generate different types of financial time series data to test our statistical tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample sizes\n",
    "n = 1000\n",
    "\n",
    "# 1. Normal data (Gaussian white noise)\n",
    "normal_data = np.random.standard_normal(n)\n",
    "\n",
    "# 2. Student's t-distributed data (heavy tails)\n",
    "t_data = stats.t.rvs(df=5, size=n)  # t-distribution with 5 degrees of freedom\n",
    "\n",
    "# 3. Skewed data\n",
    "skewed_data = stats.skewnorm.rvs(a=5, size=n)  # Positively skewed data\n",
    "\n",
    "# 4. AR(1) process (autocorrelated data)\n",
    "ar_data = np.zeros(n)\n",
    "ar_data[0] = np.random.standard_normal()\n",
    "phi = 0.7  # AR coefficient\n",
    "for t in range(1, n):\n",
    "    ar_data[t] = phi * ar_data[t-1] + np.random.standard_normal()\n",
    "\n",
    "# 5. GARCH(1,1) process (volatility clustering)\n",
    "garch_data = np.zeros(n)\n",
    "volatility = np.zeros(n)\n",
    "volatility[0] = 0.01\n",
    "omega, alpha, beta = 0.00001, 0.1, 0.85  # GARCH parameters\n",
    "for t in range(1, n):\n",
    "    volatility[t] = np.sqrt(omega + alpha * garch_data[t-1]**2 + beta * volatility[t-1]**2)\n",
    "    garch_data[t] = volatility[t] * np.random.standard_normal()\n",
    "\n",
    "# Create a DataFrame with all the data\n",
    "dates = pd.date_range(start='2020-01-01', periods=n, freq='D')\n",
    "df = pd.DataFrame({\n",
    "    'normal': normal_data,\n",
    "    't_dist': t_data,\n",
    "    'skewed': skewed_data,\n",
    "    'ar1': ar_data,\n",
    "    'garch': garch_data\n",
    "}, index=dates)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different time series\n",
    "fig, axes = plt.subplots(5, 1, figsize=(12, 15), sharex=True)\n",
    "\n",
    "df['normal'].plot(ax=axes[0], title='Normal Data (Gaussian White Noise)')\n",
    "df['t_dist'].plot(ax=axes[1], title=\"Student's t-Distributed Data (Heavy Tails)\")\n",
    "df['skewed'].plot(ax=axes[2], title='Skewed Data')\n",
    "df['ar1'].plot(ax=axes[3], title='AR(1) Process (Autocorrelated Data)')\n",
    "df['garch'].plot(ax=axes[4], title='GARCH(1,1) Process (Volatility Clustering)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('Value')\n",
    "    \n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normality Tests\n",
    "\n",
    "### 2.1 Jarque-Bera Test\n",
    "\n",
    "The Jarque-Bera test examines whether data has skewness and kurtosis matching a normal distribution. The test statistic is defined as:\n",
    "\n",
    "$$JB = \\frac{n}{6} \\left( S^2 + \\frac{(K-3)^2}{4} \\right)$$\n",
    "\n",
    "where $n$ is the sample size, $S$ is the sample skewness, and $K$ is the sample kurtosis.\n",
    "\n",
    "Under the null hypothesis of normality, the JB statistic follows a chi-squared distribution with 2 degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to test and visualize Jarque-Bera results\n",
    "def test_normality_jb(data, title):\n",
    "    # Calculate Jarque-Bera statistic\n",
    "    jb_stat, p_value = jarque_bera(data)\n",
    "    \n",
    "    # Calculate skewness and kurtosis for reference\n",
    "    skewness = stats.skew(data)\n",
    "    kurtosis = stats.kurtosis(data, fisher=False)  # Use non-Fisher definition (raw kurtosis)\n",
    "    \n",
    "    # Create a histogram with normal distribution overlay\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot histogram\n",
    "    n, bins, patches = plt.hist(data, bins=50, density=True, alpha=0.7, color='blue')\n",
    "    \n",
    "    # Plot normal distribution\n",
    "    mu, std = np.mean(data), np.std(data)\n",
    "    x = np.linspace(mu - 4*std, mu + 4*std, 100)\n",
    "    plt.plot(x, stats.norm.pdf(x, mu, std), 'r-', linewidth=2, \n",
    "             label='Normal Distribution')\n",
    "    \n",
    "    # Add test results to the plot\n",
    "    result_text = f\"Jarque-Bera Statistic: {jb_stat:.4f}\\n\"\n",
    "    result_text += f\"p-value: {p_value:.4f}\\n\"\n",
    "    result_text += f\"Skewness: {skewness:.4f}\\n\"\n",
    "    result_text += f\"Kurtosis: {kurtosis:.4f}\\n\"\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        result_text += \"Conclusion: Reject normality (p < 0.05)\"\n",
    "    else:\n",
    "        result_text += \"Conclusion: Cannot reject normality (p ≥ 0.05)\"\n",
    "    \n",
    "    # Add a text box with the results\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    plt.text(0.05, 0.95, result_text, transform=plt.gca().transAxes, fontsize=12,\n",
    "             verticalalignment='top', bbox=props)\n",
    "    \n",
    "    plt.title(f'Jarque-Bera Test: {title}')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return jb_stat, p_value, skewness, kurtosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normality for each dataset\n",
    "test_normality_jb(df['normal'], 'Normal Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normality_jb(df['t_dist'], \"Student's t-Distributed Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normality_jb(df['skewed'], 'Skewed Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Comparing Jarque-Bera Results Across Datasets\n",
    "\n",
    "Let's compare the Jarque-Bera test results for all our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all datasets and collect results\n",
    "jb_results = {}\n",
    "for col in df.columns:\n",
    "    jb_stat, p_value, skewness, kurtosis = test_normality_jb(df[col], col)\n",
    "    jb_results[col] = {\n",
    "        'JB Statistic': jb_stat,\n",
    "        'p-value': p_value,\n",
    "        'Skewness': skewness,\n",
    "        'Kurtosis': kurtosis,\n",
    "        'Reject Normality': 'Yes' if p_value < 0.05 else 'No'\n",
    "    }\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "jb_results_df = pd.DataFrame(jb_results).T\n",
    "jb_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the JB statistics and p-values\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot JB statistics\n",
    "ax1.bar(jb_results_df.index, jb_results_df['JB Statistic'])\n",
    "ax1.set_title('Jarque-Bera Test Statistics')\n",
    "ax1.set_ylabel('JB Statistic')\n",
    "ax1.set_xticklabels(jb_results_df.index, rotation=45)\n",
    "\n",
    "# Add a horizontal line at the 5% critical value (chi-squared with 2 df)\n",
    "critical_value = stats.chi2.ppf(0.95, 2)\n",
    "ax1.axhline(y=critical_value, color='r', linestyle='--', \n",
    "            label=f'5% Critical Value: {critical_value:.4f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot p-values\n",
    "ax2.bar(jb_results_df.index, jb_results_df['p-value'])\n",
    "ax2.set_title('Jarque-Bera p-values')\n",
    "ax2.set_ylabel('p-value')\n",
    "ax2.set_xticklabels(jb_results_df.index, rotation=45)\n",
    "\n",
    "# Add a horizontal line at the 5% significance level\n",
    "ax2.axhline(y=0.05, color='r', linestyle='--', label='5% Significance Level')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Asynchronous Jarque-Bera Test\n",
    "\n",
    "The MFE Toolbox provides asynchronous versions of statistical tests for non-blocking execution. This is particularly useful for long-running tests or when processing multiple datasets in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an asynchronous function to run Jarque-Bera tests\n",
    "async def run_async_jb_tests(data_dict):\n",
    "    results = {}\n",
    "    \n",
    "    # Create tasks for all datasets\n",
    "    tasks = {\n",
    "        name: jarque_bera_async(data) for name, data in data_dict.items()\n",
    "    }\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    for name, task in tasks.items():\n",
    "        jb_stat, p_value = await task\n",
    "        results[name] = {\n",
    "            'JB Statistic': jb_stat,\n",
    "            'p-value': p_value,\n",
    "            'Reject Normality': 'Yes' if p_value < 0.05 else 'No'\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# Run the asynchronous tests\n",
    "async_results = await run_async_jb_tests(df.to_dict('series'))\n",
    "async_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distribution Tests\n",
    "\n",
    "### 3.1 Kolmogorov-Smirnov Test\n",
    "\n",
    "The Kolmogorov-Smirnov (KS) test compares a sample with a reference probability distribution. The test statistic is defined as the maximum absolute difference between the empirical CDF of the sample and the reference CDF:\n",
    "\n",
    "$$D_n = \\sup_x |F_n(x) - F(x)|$$\n",
    "\n",
    "where $F_n(x)$ is the empirical CDF and $F(x)$ is the reference CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to test and visualize Kolmogorov-Smirnov results\n",
    "def test_distribution_ks(data, cdf, cdf_name, title):\n",
    "    # Calculate KS statistic\n",
    "    ks_stat, p_value = kolmogorov_smirnov(data, cdf)\n",
    "    \n",
    "    # Create a plot to visualize the empirical CDF vs. the reference CDF\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Sort the data for ECDF\n",
    "    sorted_data = np.sort(data)\n",
    "    \n",
    "    # Calculate ECDF\n",
    "    ecdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    \n",
    "    # Calculate reference CDF values\n",
    "    ref_cdf = np.array([cdf(x) for x in sorted_data])\n",
    "    \n",
    "    # Plot ECDFs\n",
    "    plt.plot(sorted_data, ecdf, 'b-', linewidth=2, label='Empirical CDF')\n",
    "    plt.plot(sorted_data, ref_cdf, 'r-', linewidth=2, label=f'Reference CDF ({cdf_name})')\n",
    "    \n",
    "    # Find the point of maximum difference\n",
    "    max_diff_idx = np.argmax(np.abs(ecdf - ref_cdf))\n",
    "    max_diff_x = sorted_data[max_diff_idx]\n",
    "    max_diff_y1 = ecdf[max_diff_idx]\n",
    "    max_diff_y2 = ref_cdf[max_diff_idx]\n",
    "    \n",
    "    # Plot the maximum difference\n",
    "    plt.plot([max_diff_x, max_diff_x], [max_diff_y1, max_diff_y2], 'g-', linewidth=2, \n",
    "             label=f'Max Difference: {ks_stat:.4f}')\n",
    "    plt.scatter([max_diff_x], [max_diff_y1], color='green', s=50)\n",
    "    plt.scatter([max_diff_x], [max_diff_y2], color='green', s=50)\n",
    "    \n",
    "    # Add test results to the plot\n",
    "    result_text = f\"KS Statistic: {ks_stat:.4f}\\n\"\n",
    "    result_text += f\"p-value: {p_value:.4f}\\n\"\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        result_text += f\"Conclusion: Reject {cdf_name} distribution (p < 0.05)\\n\"\n",
    "    else:\n",
    "        result_text += f\"Conclusion: Cannot reject {cdf_name} distribution (p ≥ 0.05)\\n\"\n",
    "    \n",
    "    # Add a text box with the results\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    plt.text(0.05, 0.95, result_text, transform=plt.gca().transAxes, fontsize=12,\n",
    "             verticalalignment='top', bbox=props)\n",
    "    \n",
    "    plt.title(f'Kolmogorov-Smirnov Test: {title}')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return ks_stat, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normal data against normal distribution\n",
    "# Create a normal CDF function\n",
    "normal_cdf = lambda x: stats.norm.cdf(x, loc=np.mean(df['normal']), scale=np.std(df['normal']))\n",
    "\n",
    "test_distribution_ks(df['normal'], normal_cdf, 'Normal', 'Normal Data vs. Normal Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test t-distributed data against normal distribution (should reject)\n",
    "t_mean, t_std = np.mean(df['t_dist']), np.std(df['t_dist'])\n",
    "normal_cdf_for_t = lambda x: stats.norm.cdf(x, loc=t_mean, scale=t_std)\n",
    "\n",
    "test_distribution_ks(df['t_dist'], normal_cdf_for_t, 'Normal', \"t-Distributed Data vs. Normal Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test t-distributed data against t distribution (should not reject)\n",
    "t_cdf = lambda x: stats.t.cdf(x, df=5, loc=t_mean, scale=t_std)\n",
    "\n",
    "test_distribution_ks(df['t_dist'], t_cdf, 't(5)', \"t-Distributed Data vs. t(5) Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Berkowitz Test\n",
    "\n",
    "The Berkowitz test is particularly useful for evaluating density forecasts. It transforms the data using a specified CDF and then tests whether the transformed data follows a standard normal distribution using an AR(1) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to test and visualize Berkowitz test results\n",
    "def test_distribution_berkowitz(data, cdf, cdf_name, title):\n",
    "    # Calculate Berkowitz statistic\n",
    "    berk_stat, p_value = berkowitz(data, cdf)\n",
    "    \n",
    "    # Transform the data using the CDF and then the inverse normal CDF\n",
    "    u = np.array([cdf(x) for x in data])\n",
    "    z = stats.norm.ppf(u)\n",
    "    \n",
    "    # Create plots to visualize the transformation\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot original data histogram\n",
    "    ax1.hist(data, bins=50, density=True, alpha=0.7, color='blue')\n",
    "    ax1.set_title('Original Data')\n",
    "    ax1.set_xlabel('Value')\n",
    "    ax1.set_ylabel('Density')\n",
    "    \n",
    "    # Plot uniform transformation (PIT)\n",
    "    ax2.hist(u, bins=50, density=True, alpha=0.7, color='green')\n",
    "    ax2.plot([0, 1], [1, 1], 'r-', linewidth=2, label='Uniform(0,1)')\n",
    "    ax2.set_title('Probability Integral Transform (PIT)')\n",
    "    ax2.set_xlabel('Probability')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.legend()\n",
    "    ax2.set_xlim(0, 1)\n",
    "    \n",
    "    # Plot normal transformation\n",
    "    ax3.hist(z, bins=50, density=True, alpha=0.7, color='purple')\n",
    "    x = np.linspace(-4, 4, 100)\n",
    "    ax3.plot(x, stats.norm.pdf(x), 'r-', linewidth=2, label='Standard Normal')\n",
    "    ax3.set_title('Normal Quantile Transform')\n",
    "    ax3.set_xlabel('Value')\n",
    "    ax3.set_ylabel('Density')\n",
    "    ax3.legend()\n",
    "    \n",
    "    plt.suptitle(f'Berkowitz Test: {title}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Display test results\n",
    "    print(f\"Berkowitz Test Results for {title}:\")\n",
    "    print(f\"Test Statistic: {berk_stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"Conclusion: Reject {cdf_name} distribution (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"Conclusion: Cannot reject {cdf_name} distribution (p ≥ 0.05)\")\n",
    "    print(\"\n\")\n",
    "    \n",
    "    return berk_stat, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normal data against normal distribution\n",
    "test_distribution_berkowitz(df['normal'], normal_cdf, 'Normal', 'Normal Data vs. Normal Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test t-distributed data against normal distribution (should reject)\n",
    "test_distribution_berkowitz(df['t_dist'], normal_cdf_for_t, 'Normal', \"t-Distributed Data vs. Normal Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test t-distributed data against t distribution (should not reject)\n",
    "test_distribution_berkowitz(df['t_dist'], t_cdf, 't(5)', \"t-Distributed Data vs. t(5) Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Serial Correlation Tests\n",
    "\n",
    "### 4.1 Ljung-Box Test\n",
    "\n",
    "The Ljung-Box test examines whether there is significant autocorrelation in a time series up to a specified number of lags. The test statistic is defined as:\n",
    "\n",
    "$$Q = n(n+2) \\sum_{k=1}^{h} \\frac{\\hat{\\rho}_k^2}{n-k}$$\n",
    "\n",
    "where $n$ is the sample size, $h$ is the number of lags, and $\\hat{\\rho}_k$ is the sample autocorrelation at lag $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to test and visualize Ljung-Box results\n",
    "def test_autocorrelation_lb(data, lags, title):\n",
    "    # Calculate Ljung-Box statistic\n",
    "    lb_stat, p_value = ljung_box(data, lags=lags)\n",
    "    \n",
    "    # Calculate autocorrelation function\n",
    "    acf_values = np.array([1.0] + [np.corrcoef(data[:-i], data[i:])[0, 1] for i in range(1, lags+1)])\n",
    "    \n",
    "    # Create a plot to visualize the ACF\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot ACF\n",
    "    plt.bar(range(lags+1), acf_values, width=0.3, color='blue', alpha=0.7)\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Add confidence bands\n",
    "    conf_level = 1.96 / np.sqrt(len(data))  # 95% confidence bands\n",
    "    plt.axhline(y=conf_level, color='red', linestyle='--', alpha=0.7, \n",
    "                label=f'95% Confidence Bands (±{conf_level:.4f})')\n",
    "    plt.axhline(y=-conf_level, color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add test results to the plot\n",
    "    result_text = f\"Ljung-Box Statistic (Q): {lb_stat:.4f}\\n\"\n",
    "    result_text += f\"p-value: {p_value:.4f}\\n\"\n",
    "    result_text += f\"Lags: {lags}\\n\"\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        result_text += \"Conclusion: Reject no autocorrelation (p < 0.05)\"\n",
    "    else:\n",
    "        result_text += \"Conclusion: Cannot reject no autocorrelation (p ≥ 0.05)\"\n",
    "    \n",
    "    # Add a text box with the results\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    plt.text(0.05, 0.95, result_text, transform=plt.gca().transAxes, fontsize=12,\n",
    "             verticalalignment='top', bbox=props)\n",
    "    \n",
    "    plt.title(f'Ljung-Box Test: {title}')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(range(lags+1))\n",
    "    plt.xlim(-0.5, lags+0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    return lb_stat, p_value, acf_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test white noise data (should not reject)\n",
    "test_autocorrelation_lb(df['normal'], lags=20, title='Normal Data (White Noise)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AR(1) process (should reject)\n",
    "test_autocorrelation_lb(df['ar1'], lags=20, title='AR(1) Process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GARCH process returns (should not show significant autocorrelation)\n",
    "test_autocorrelation_lb(df['garch'], lags=20, title='GARCH(1,1) Process Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GARCH process squared returns (should show significant autocorrelation)\n",
    "test_autocorrelation_lb(df['garch']**2, lags=20, title='GARCH(1,1) Process Squared Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Ljung-Box Test with Multiple Lags\n",
    "\n",
    "Let's examine how the Ljung-Box test results change with different lag specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple lags\n",
    "lag_values = [5, 10, 15, 20, 25, 30]\n",
    "lb_results = {}\n",
    "\n",
    "for series_name in ['normal', 'ar1', 'garch', 'garch_squared']:\n",
    "    # Use the original series or create squared returns for GARCH\n",
    "    if series_name == 'garch_squared':\n",
    "        series = df['garch']**2\n",
    "        display_name = 'GARCH Squared Returns'\n",
    "    else:\n",
    "        series = df[series_name]\n",
    "        display_name = series_name.capitalize()\n",
    "    \n",
    "    # Test with different lags\n",
    "    lb_results[display_name] = {}\n",
    "    for lag in lag_values:\n",
    "        lb_stat, p_value = ljung_box(series, lags=lag)\n",
    "        lb_results[display_name][lag] = {\n",
    "            'Q-statistic': lb_stat,\n",
    "            'p-value': p_value,\n",
    "            'Reject': 'Yes' if p_value < 0.05 else 'No'\n",
    "        }\n",
    "\n",
    "# Create a DataFrame with p-values for different lags\n",
    "p_values = {}\n",
    "for series_name, results in lb_results.items():\n",
    "    p_values[series_name] = [results[lag]['p-value'] for lag in lag_values]\n",
    "\n",
    "p_values_df = pd.DataFrame(p_values, index=lag_values)\n",
    "p_values_df.index.name = 'Lags'\n",
    "p_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize p-values for different lags\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for col in p_values_df.columns:\n",
    "    plt.plot(p_values_df.index, p_values_df[col], marker='o', label=col)\n",
    "\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='5% Significance Level')\n",
    "plt.title('Ljung-Box Test p-values for Different Lags')\n",
    "plt.xlabel('Number of Lags')\n",
    "plt.ylabel('p-value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(lag_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ARCH Effect Tests\n",
    "\n",
    "### 5.1 Lagrange Multiplier (LM) Test\n",
    "\n",
    "The Lagrange Multiplier test examines whether there are ARCH effects (conditional heteroskedasticity) in a time series. It regresses squared residuals on lagged squared residuals and tests the joint significance of all lagged squared residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to test and visualize LM test results\n",
    "def test_arch_effects_lm(data, lags, title):\n",
    "    # Calculate LM statistic\n",
    "    lm_stat, p_value = lm_test(data, lags=lags)\n",
    "    \n",
    "    # Calculate autocorrelation function of squared returns\n",
    "    squared_data = data**2\n",
    "    acf_values = np.array([1.0] + [np.corrcoef(squared_data[:-i], squared_data[i:])[0, 1] \n",
    "                                   for i in range(1, lags+1)])\n",
    "    \n",
    "    # Create plots to visualize the data and squared data\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12))\n",
    "    \n",
    "    # Plot the original time series\n",
    "    ax1.plot(range(len(data)), data)\n",
    "    ax1.set_title(f'Original Time Series: {title}')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Value')\n",
    "    \n",
    "    # Plot the squared time series\n",
    "    ax2.plot(range(len(squared_data)), squared_data)\n",
    "    ax2.set_title(f'Squared Time Series: {title}')\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Squared Value')\n",
    "    \n",
    "    # Plot ACF of squared data\n",
    "    ax3.bar(range(lags+1), acf_values, width=0.3, color='blue', alpha=0.7)\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Add confidence bands\n",
    "    conf_level = 1.96 / np.sqrt(len(data))  # 95% confidence bands\n",
    "    ax3.axhline(y=conf_level, color='red', linestyle='--', alpha=0.7, \n",
    "                label=f'95% Confidence Bands (±{conf_level:.4f})')\n",
    "    ax3.axhline(y=-conf_level, color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    ax3.set_title(f'ACF of Squared Time Series: {title}')\n",
    "    ax3.set_xlabel('Lag')\n",
    "    ax3.set_ylabel('Autocorrelation')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_xticks(range(lags+1))\n",
    "    ax3.set_xlim(-0.5, lags+0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display test results\n",
    "    print(f\"Lagrange Multiplier (ARCH) Test Results for {title}:\")\n",
    "    print(f\"LM Statistic: {lm_stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    print(f\"Lags: {lags}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"Conclusion: Reject no ARCH effects (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"Conclusion: Cannot reject no ARCH effects (p ≥ 0.05)\")\n",
    "    print(\"\n\")\n",
    "    \n",
    "    return lm_stat, p_value, acf_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test white noise data (should not reject)\n",
    "test_arch_effects_lm(df['normal'], lags=10, title='Normal Data (White Noise)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GARCH process (should reject)\n",
    "test_arch_effects_lm(df['garch'], lags=10, title='GARCH(1,1) Process')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Comparing LM Test Results Across Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all datasets with LM test\n",
    "lm_results = {}\n",
    "for col in df.columns:\n",
    "    lm_stat, p_value, _ = test_arch_effects_lm(df[col], lags=10, title=col)\n",
    "    lm_results[col] = {\n",
    "        'LM Statistic': lm_stat,\n",
    "        'p-value': p_value,\n",
    "        'Reject No ARCH': 'Yes' if p_value < 0.05 else 'No'\n",
    "    }\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "lm_results_df = pd.DataFrame(lm_results).T\n",
    "lm_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the LM statistics and p-values\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot LM statistics\n",
    "ax1.bar(lm_results_df.index, lm_results_df['LM Statistic'])\n",
    "ax1.set_title('LM Test Statistics')\n",
    "ax1.set_ylabel('LM Statistic')\n",
    "ax1.set_xticklabels(lm_results_df.index, rotation=45)\n",
    "\n",
    "# Add a horizontal line at the 5% critical value (chi-squared with 10 df)\n",
    "critical_value = stats.chi2.ppf(0.95, 10)  # 10 lags\n",
    "ax1.axhline(y=critical_value, color='r', linestyle='--', \n",
    "            label=f'5% Critical Value: {critical_value:.4f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot p-values\n",
    "ax2.bar(lm_results_df.index, lm_results_df['p-value'])\n",
    "ax2.set_title('LM Test p-values')\n",
    "ax2.set_ylabel('p-value')\n",
    "ax2.set_xticklabels(lm_results_df.index, rotation=45)\n",
    "\n",
    "# Add a horizontal line at the 5% significance level\n",
    "ax2.axhline(y=0.05, color='r', linestyle='--', label='5% Significance Level')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Residual Diagnostics\n",
    "\n",
    "Statistical tests are often used to validate model assumptions by testing the residuals. Let's fit some models to our data and test the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an AR(1) model to the AR(1) process\n",
    "ar_model = ARMA(ar_order=1, ma_order=0, include_constant=True)\n",
    "ar_results = ar_model.fit(df['ar1'])\n",
    "\n",
    "# Get the residuals\n",
    "ar_residuals = ar_results.residuals\n",
    "\n",
    "# Display model summary\n",
    "print(ar_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the residuals for normality\n",
    "test_normality_jb(ar_residuals, 'AR(1) Model Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the residuals for autocorrelation\n",
    "test_autocorrelation_lb(ar_residuals, lags=20, title='AR(1) Model Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the residuals for ARCH effects\n",
    "test_arch_effects_lm(ar_residuals, lags=10, title='AR(1) Model Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a GARCH(1,1) model to the GARCH process\n",
    "garch_model = GARCH(p=1, q=1, mean='zero')\n",
    "garch_results = garch_model.fit(df['garch'])\n",
    "\n",
    "# Get the standardized residuals\n",
    "garch_std_residuals = garch_results.standardized_residuals\n",
    "\n",
    "# Display model summary\n",
    "print(garch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the standardized residuals for normality\n",
    "test_normality_jb(garch_std_residuals, 'GARCH(1,1) Model Standardized Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the standardized residuals for autocorrelation\n",
    "test_autocorrelation_lb(garch_std_residuals, lags=20, title='GARCH(1,1) Model Standardized Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the squared standardized residuals for ARCH effects\n",
    "test_arch_effects_lm(garch_std_residuals, lags=10, title='GARCH(1,1) Model Standardized Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Property-Based Testing\n",
    "\n",
    "Property-based testing is a powerful technique for validating statistical properties across a wide range of inputs. Let's demonstrate how to use property-based testing to verify distribution properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to test distribution properties\n",
    "def test_distribution_properties(dist_name, dist_params, n_samples=1000, n_tests=100):\n",
    "    # Create the distribution\n",
    "    if dist_name == 'normal':\n",
    "        dist = normal.Normal(**dist_params)\n",
    "    elif dist_name == 'student_t':\n",
    "        dist = student_t.StudentT(**dist_params)\n",
    "    elif dist_name == 'generalized_error':\n",
    "        dist = generalized_error.GeneralizedError(**dist_params)\n",
    "    elif dist_name == 'skewed_t':\n",
    "        dist = skewed_t.SkewedT(**dist_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distribution: {dist_name}\")\n",
    "    \n",
    "    # Define properties to test\n",
    "    properties = [\n",
    "        {\n",
    "            'name': 'PDF integrates to 1',\n",
    "            'test': lambda: np.abs(np.trapz(dist.pdf(np.linspace(-10, 10, 1000)), \n",
    "                                           np.linspace(-10, 10, 1000)) - 1) < 0.01\n",
    "        },\n",
    "        {\n",
    "            'name': 'CDF is monotonically increasing',\n",
    "            'test': lambda: np.all(np.diff(dist.cdf(np.linspace(-10, 10, 1000))) >= 0)\n",
    "        },\n",
    "        {\n",
    "            'name': 'CDF(x) = P(X ≤ x)',\n",
    "            'test': lambda: test_cdf_property(dist, n_samples)\n",
    "        },\n",
    "        {\n",
    "            'name': 'PDF is non-negative',\n",
    "            'test': lambda: np.all(dist.pdf(np.linspace(-10, 10, 1000)) >= 0)\n",
    "        },\n",
    "        {\n",
    "            'name': 'PPF(CDF(x)) ≈ x',\n",
    "            'test': lambda: test_ppf_cdf_property(dist)\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Run the tests\n",
    "    results = {}\n",
    "    for prop in properties:\n",
    "        success_count = 0\n",
    "        for _ in range(n_tests):\n",
    "            try:\n",
    "                if prop['test']():\n",
    "                    success_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error testing {prop['name']}: {e}\")\n",
    "        \n",
    "        results[prop['name']] = {\n",
    "            'success_rate': success_count / n_tests,\n",
    "            'passed': success_count == n_tests\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Helper function to test CDF property\n",
    "def test_cdf_property(dist, n_samples):\n",
    "    # Generate random samples\n",
    "    samples = dist.rvs(size=n_samples)\n",
    "    \n",
    "    # Test points\n",
    "    test_points = np.linspace(np.percentile(samples, 5), np.percentile(samples, 95), 10)\n",
    "    \n",
    "    # For each test point, check if CDF(x) ≈ proportion of samples ≤ x\n",
    "    for x in test_points:\n",
    "        cdf_value = dist.cdf(x)\n",
    "        empirical_cdf = np.mean(samples <= x)\n",
    "        if abs(cdf_value - empirical_cdf) > 0.05:  # Allow 5% error due to sampling\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Helper function to test PPF(CDF(x)) ≈ x property\n",
    "def test_ppf_cdf_property(dist):\n",
    "    # Test points\n",
    "    test_points = np.linspace(-3, 3, 10)\n",
    "    \n",
    "    # For each test point, check if PPF(CDF(x)) ≈ x\n",
    "    for x in test_points:\n",
    "        y = dist.ppf(dist.cdf(x))\n",
    "        if abs(x - y) > 0.01:  # Allow small numerical error\n",
    "            return False\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normal distribution properties\n",
    "normal_props = test_distribution_properties('normal', {'mu': 0, 'sigma': 1})\n",
    "\n",
    "# Test Student's t distribution properties\n",
    "t_props = test_distribution_properties('student_t', {'nu': 5})\n",
    "\n",
    "# Test generalized error distribution properties\n",
    "ged_props = test_distribution_properties('generalized_error', {'nu': 1.5})\n",
    "\n",
    "# Test skewed t distribution properties\n",
    "skewed_t_props = test_distribution_properties('skewed_t', {'nu': 5, 'lambda': 0.3})\n",
    "\n",
    "# Combine results\n",
    "all_props = {\n",
    "    'Normal': normal_props,\n",
    "    \"Student's t\": t_props,\n",
    "    'Generalized Error': ged_props,\n",
    "    'Skewed t': skewed_t_props\n",
    "}\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "prop_results = {}\n",
    "for dist_name, props in all_props.items():\n",
    "    for prop_name, result in props.items():\n",
    "        if prop_name not in prop_results:\n",
    "            prop_results[prop_name] = {}\n",
    "        prop_results[prop_name][dist_name] = 'Pass' if result['passed'] else 'Fail'\n",
    "\n",
    "prop_results_df = pd.DataFrame(prop_results)\n",
    "prop_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Asynchronous Testing\n",
    "\n",
    "The MFE Toolbox provides asynchronous versions of all statistical tests, which can be useful for non-blocking execution in interactive environments or when processing multiple datasets in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an asynchronous function to run multiple tests in parallel\n",
    "async def run_all_tests_async(data):\n",
    "    # Create tasks for all tests\n",
    "    tasks = {\n",
    "        'Jarque-Bera': jarque_bera_async(data),\n",
    "        'Kolmogorov-Smirnov': kolmogorov_smirnov_async(data, stats.norm.cdf),\n",
    "        'Ljung-Box': ljung_box_async(data, lags=10),\n",
    "        'LM Test': lm_test_async(data, lags=10)\n",
    "    }\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    results = {}\n",
    "    for name, task in tasks.items():\n",
    "        stat, p_value = await task\n",
    "        results[name] = {\n",
    "            'Statistic': stat,\n",
    "            'p-value': p_value,\n",
    "            'Reject Null': 'Yes' if p_value < 0.05 else 'No'\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# Run all tests asynchronously for normal data\n",
    "normal_results = await run_all_tests_async(df['normal'])\n",
    "normal_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests asynchronously for all datasets\n",
    "async def test_all_datasets_async(data_dict):\n",
    "    results = {}\n",
    "    for name, data in data_dict.items():\n",
    "        results[name] = await run_all_tests_async(data)\n",
    "    return results\n",
    "\n",
    "# Run the tests\n",
    "all_results = await test_all_datasets_async(df.to_dict('series'))\n",
    "\n",
    "# Display results for each dataset\n",
    "for name, result in all_results.items():\n",
    "    print(f\"\nTest Results for {name}:\")\n",
    "    display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the use of statistical tests in the MFE Toolbox for analyzing financial time series data. We've covered:\n",
    "\n",
    "1. **Normality Tests**: Using the Jarque-Bera test to check if data follows a normal distribution\n",
    "2. **Distribution Tests**: Using the Kolmogorov-Smirnov and Berkowitz tests to check if data follows specific distributions\n",
    "3. **Serial Correlation Tests**: Using the Ljung-Box test to check for autocorrelation in time series\n",
    "4. **ARCH Effect Tests**: Using the Lagrange Multiplier test to check for conditional heteroskedasticity\n",
    "5. **Model Residual Diagnostics**: Testing model residuals to validate model assumptions\n",
    "6. **Property-Based Testing**: Using property-based testing to verify distribution properties\n",
    "7. **Asynchronous Testing**: Using async/await for non-blocking test execution\n",
    "\n",
    "These statistical tests are essential tools for validating model assumptions, checking distribution properties, and detecting patterns in financial data. The MFE Toolbox provides a comprehensive set of tests with a consistent interface, making it easy to incorporate them into your financial analysis workflow.\n",
    "\n",
    "The Python implementation leverages NumPy, SciPy, and Pandas for efficient computation and data handling, with performance-critical calculations accelerated using Numba's just-in-time compilation. The asynchronous interfaces enable non-blocking execution, which is particularly valuable in interactive environments or when processing multiple datasets in parallel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
