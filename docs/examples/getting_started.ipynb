{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with the MFE Toolbox\n",
    "\n",
    "This notebook provides an introduction to the MFE Toolbox, a comprehensive Python-based suite for financial econometrics, time series analysis, and risk modeling. The toolbox is a complete modernization of the original MATLAB-based toolbox, now implemented in Python 3.12 with a focus on performance, usability, and integration with the Python scientific ecosystem.\n",
    "\n",
    "## What is the MFE Toolbox?\n",
    "\n",
    "The MFE Toolbox provides a wide range of tools for financial econometrics and time series analysis, including:\n",
    "\n",
    "- **Univariate volatility modeling**: GARCH, EGARCH, TARCH, and other variants\n",
    "- **Multivariate volatility modeling**: BEKK, DCC, RARCH, and related models\n",
    "- **ARMA/ARMAX time series modeling and forecasting**\n",
    "- **Bootstrap methods for dependent data**\n",
    "- **Non-parametric volatility estimation** (realized volatility)\n",
    "- **Classical statistical tests and distributions**\n",
    "- **Vector autoregression (VAR) analysis**\n",
    "- **Principal component analysis and cross-sectional econometrics**\n",
    "\n",
    "This notebook will guide you through the installation process and demonstrate basic usage of the toolbox's core functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "The MFE Toolbox can be installed using pip, Python's package installer. It's recommended to install the toolbox in a virtual environment to avoid conflicts with other packages.\n",
    "\n",
    "### Using pip\n",
    "\n",
    "```bash\n",
    "pip install mfe-toolbox\n",
    "```\n",
    "\n",
    "### Using a virtual environment\n",
    "\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "python -m venv mfe_env\n",
    "\n",
    "# Activate the environment (Windows)\n",
    "mfe_env\\Scripts\\activate\n",
    "\n",
    "# Activate the environment (Unix/Linux/macOS)\n",
    "source mfe_env/bin/activate\n",
    "\n",
    "# Install MFE Toolbox in the virtual environment\n",
    "pip install mfe-toolbox\n",
    "```\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "The MFE Toolbox depends on several Python packages that will be automatically installed:\n",
    "\n",
    "- NumPy (≥1.26.0): For efficient array operations and linear algebra\n",
    "- SciPy (≥1.11.3): For scientific computing and optimization routines\n",
    "- Pandas (≥2.1.1): For time series data handling and analysis\n",
    "- Statsmodels (≥0.14.0): For econometric modeling and statistical analysis\n",
    "- Numba (≥0.58.0): For JIT compilation of performance-critical functions\n",
    "- matplotlib (≥3.8.0): For visualization\n",
    "- PyQt6 (≥6.5.0): For GUI components (optional, only needed for the ARMAX interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the MFE Toolbox\n",
    "\n",
    "Once installed, you can import the MFE Toolbox in your Python code. Let's start by importing the main package and checking the version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mfe\n",
    "\n",
    "print(f\"MFE Toolbox version: {mfe.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MFE Toolbox is organized into several subpackages:\n",
    "\n",
    "- `mfe.core`: Core functionality and base classes\n",
    "- `mfe.models`: Implementation of econometric models\n",
    "- `mfe.utils`: Helper functions for data transformation and analysis\n",
    "- `mfe.ui`: User interface components\n",
    "\n",
    "Let's import some commonly used components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import commonly used models directly from the mfe package\n",
    "from mfe import GARCH, ARMA, DCC, BlockBootstrap, RealizedVariance\n",
    "\n",
    "# Import specific modules as needed\n",
    "from mfe.models.univariate import EGARCH, TARCH\n",
    "from mfe.models.time_series import VAR\n",
    "from mfe.models.bootstrap import StationaryBootstrap\n",
    "from mfe.models.distributions import StudentT\n",
    "\n",
    "# Import utility functions\n",
    "from mfe.utils import matrix_ops, covariance\n",
    "\n",
    "# Import NumPy and Pandas for data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Data\n",
    "\n",
    "The MFE Toolbox works with NumPy arrays and Pandas DataFrames for data handling. Let's create some sample financial data to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a date range for our time series\n",
    "dates = pd.date_range(start='2020-01-01', periods=1000, freq='D')\n",
    "\n",
    "# Generate simulated returns with volatility clustering\n",
    "# (This is a simple AR(1)-GARCH(1,1) process)\n",
    "n = len(dates)\n",
    "returns = np.zeros(n)\n",
    "volatility = np.zeros(n)\n",
    "volatility[0] = 0.01\n",
    "\n",
    "# Parameters\n",
    "omega = 0.00001\n",
    "alpha = 0.1\n",
    "beta = 0.85\n",
    "phi = 0.2  # AR(1) coefficient\n",
    "\n",
    "for t in range(1, n):\n",
    "    # Volatility equation\n",
    "    volatility[t] = np.sqrt(omega + alpha * returns[t-1]**2 + beta * volatility[t-1]**2)\n",
    "    \n",
    "    # Return equation with AR(1) component\n",
    "    returns[t] = phi * returns[t-1] + volatility[t] * np.random.standard_normal()\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'returns': returns,\n",
    "    'volatility': volatility\n",
    "}, index=dates)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the returns and volatility\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "ax1.plot(df.index, df['returns'])\n",
    "ax1.set_title('Simulated Returns')\n",
    "ax1.set_ylabel('Returns')\n",
    "\n",
    "ax2.plot(df.index, df['volatility'])\n",
    "ax2.set_title('True Volatility')\n",
    "ax2.set_ylabel('Volatility')\n",
    "ax2.set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Univariate Volatility Modeling with GARCH\n",
    "\n",
    "Let's start with a basic example of fitting a GARCH(1,1) model to our simulated returns data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GARCH(1,1) model\n",
    "garch_model = GARCH(p=1, q=1, mean='constant')\n",
    "\n",
    "# Fit the model to our returns data\n",
    "garch_results = garch_model.fit(df['returns'])\n",
    "\n",
    "# Display the model summary\n",
    "print(garch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the estimated conditional volatility\n",
    "df['garch_volatility'] = np.sqrt(garch_results.conditional_variance)\n",
    "\n",
    "# Plot the true volatility vs. estimated volatility\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.index, df['volatility'], label='True Volatility')\n",
    "plt.plot(df.index, df['garch_volatility'], label='GARCH(1,1) Volatility', alpha=0.7)\n",
    "plt.title('True vs. GARCH(1,1) Estimated Volatility')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with GARCH\n",
    "\n",
    "Now let's generate volatility forecasts using our fitted GARCH model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30-day ahead forecasts\n",
    "forecast_horizon = 30\n",
    "forecasts = garch_results.forecast(horizon=forecast_horizon)\n",
    "\n",
    "# Create a date range for the forecast period\n",
    "forecast_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=forecast_horizon, freq='D')\n",
    "\n",
    "# Create a DataFrame for the forecasts\n",
    "forecast_df = pd.DataFrame({\n",
    "    'volatility_forecast': np.sqrt(forecasts.variance),\n",
    "    'volatility_lower': np.sqrt(forecasts.variance_lower),\n",
    "    'volatility_upper': np.sqrt(forecasts.variance_upper)\n",
    "}, index=forecast_dates)\n",
    "\n",
    "# Plot the historical volatility and forecasts\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot historical volatility (last 90 days)\n",
    "plt.plot(df.index[-90:], df['garch_volatility'][-90:], label='Historical Volatility')\n",
    "\n",
    "# Plot forecasts\n",
    "plt.plot(forecast_df.index, forecast_df['volatility_forecast'], label='Volatility Forecast', color='red')\n",
    "plt.fill_between(forecast_df.index, \n",
    "                 forecast_df['volatility_lower'], \n",
    "                 forecast_df['volatility_upper'], \n",
    "                 color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "\n",
    "plt.title('GARCH(1,1) Volatility Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Time Series Analysis with ARMA\n",
    "\n",
    "Now let's fit an ARMA model to our returns data to capture the serial correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ARMA(1,1) model\n",
    "arma_model = ARMA(ar_order=1, ma_order=1, include_constant=True)\n",
    "\n",
    "# Fit the model to our returns data\n",
    "arma_results = arma_model.fit(df['returns'])\n",
    "\n",
    "# Display the model summary\n",
    "print(arma_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ACF and PACF of the returns\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# ACF\n",
    "lags = 20\n",
    "acf_values = arma_results.acf(lags=lags)\n",
    "ax1.bar(range(lags+1), acf_values, width=0.3)\n",
    "ax1.axhline(y=0, linestyle='-', color='black', alpha=0.3)\n",
    "ax1.axhline(y=1.96/np.sqrt(len(df)), linestyle='--', color='blue', alpha=0.7)\n",
    "ax1.axhline(y=-1.96/np.sqrt(len(df)), linestyle='--', color='blue', alpha=0.7)\n",
    "ax1.set_title('Autocorrelation Function (ACF)')\n",
    "ax1.set_xlabel('Lag')\n",
    "ax1.set_ylabel('Correlation')\n",
    "\n",
    "# PACF\n",
    "pacf_values = arma_results.pacf(lags=lags)\n",
    "ax2.bar(range(lags+1), pacf_values, width=0.3)\n",
    "ax2.axhline(y=0, linestyle='-', color='black', alpha=0.3)\n",
    "ax2.axhline(y=1.96/np.sqrt(len(df)), linestyle='--', color='blue', alpha=0.7)\n",
    "ax2.axhline(y=-1.96/np.sqrt(len(df)), linestyle='--', color='blue', alpha=0.7)\n",
    "ax2.set_title('Partial Autocorrelation Function (PACF)')\n",
    "ax2.set_xlabel('Lag')\n",
    "ax2.set_ylabel('Partial Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts from the ARMA model\n",
    "arma_forecasts = arma_results.forecast(horizon=30)\n",
    "\n",
    "# Create a DataFrame for the forecasts\n",
    "arma_forecast_df = pd.DataFrame({\n",
    "    'point_forecast': arma_forecasts.mean,\n",
    "    'lower_bound': arma_forecasts.mean_lower,\n",
    "    'upper_bound': arma_forecasts.mean_upper\n",
    "}, index=forecast_dates)\n",
    "\n",
    "# Plot the historical returns and forecasts\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot historical returns (last 90 days)\n",
    "plt.plot(df.index[-90:], df['returns'][-90:], label='Historical Returns')\n",
    "\n",
    "# Plot forecasts\n",
    "plt.plot(arma_forecast_df.index, arma_forecast_df['point_forecast'], label='Return Forecast', color='green')\n",
    "plt.fill_between(arma_forecast_df.index, \n",
    "                 arma_forecast_df['lower_bound'], \n",
    "                 arma_forecast_df['upper_bound'], \n",
    "                 color='green', alpha=0.2, label='95% Confidence Interval')\n",
    "\n",
    "plt.title('ARMA(1,1) Return Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Bootstrap Methods\n",
    "\n",
    "The MFE Toolbox provides bootstrap methods for dependent data. Let's use the block bootstrap to estimate the standard error of the mean return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a block bootstrap object\n",
    "block_size = 20  # Block size for the bootstrap\n",
    "n_bootstraps = 1000  # Number of bootstrap samples\n",
    "\n",
    "bootstrap = BlockBootstrap(block_size=block_size)\n",
    "\n",
    "# Generate bootstrap samples\n",
    "bootstrap_samples = bootstrap.generate_samples(df['returns'].values, n_bootstraps)\n",
    "\n",
    "# Calculate the mean for each bootstrap sample\n",
    "bootstrap_means = np.mean(bootstrap_samples, axis=1)\n",
    "\n",
    "# Calculate the standard error of the mean\n",
    "bootstrap_std_error = np.std(bootstrap_means, ddof=1)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "bootstrap_ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "bootstrap_ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Sample Mean: {np.mean(df['returns']):.6f}\")\n",
    "print(f\"Bootstrap Standard Error: {bootstrap_std_error:.6f}\")\n",
    "print(f\"95% Confidence Interval: [{bootstrap_ci_lower:.6f}, {bootstrap_ci_upper:.6f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bootstrap distribution of the mean\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bootstrap_means, bins=50, alpha=0.7, color='blue')\n",
    "plt.axvline(x=np.mean(df['returns']), color='red', linestyle='--', label='Sample Mean')\n",
    "plt.axvline(x=bootstrap_ci_lower, color='green', linestyle='--', label='2.5% Percentile')\n",
    "plt.axvline(x=bootstrap_ci_upper, color='green', linestyle='--', label='97.5% Percentile')\n",
    "plt.title('Bootstrap Distribution of the Mean Return')\n",
    "plt.xlabel('Mean Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Multivariate Volatility Modeling\n",
    "\n",
    "Let's generate some multivariate return data and fit a DCC-GARCH model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multivariate return data (2 assets)\n",
    "n_assets = 2\n",
    "n_obs = 1000\n",
    "\n",
    "# Set correlation between assets\n",
    "correlation = 0.5\n",
    "cov_matrix = np.array([[1.0, correlation], [correlation, 1.0]])\n",
    "\n",
    "# Generate correlated random returns\n",
    "np.random.seed(42)\n",
    "multi_returns = np.random.multivariate_normal(mean=np.zeros(n_assets), cov=cov_matrix, size=n_obs)\n",
    "\n",
    "# Apply GARCH effects to each series\n",
    "volatility = np.ones((n_obs, n_assets)) * 0.01\n",
    "returns = np.zeros((n_obs, n_assets))\n",
    "\n",
    "# GARCH parameters for each asset\n",
    "omega = np.array([0.00001, 0.00002])\n",
    "alpha = np.array([0.1, 0.15])\n",
    "beta = np.array([0.85, 0.8])\n",
    "\n",
    "for t in range(1, n_obs):\n",
    "    for i in range(n_assets):\n",
    "        volatility[t, i] = np.sqrt(omega[i] + alpha[i] * returns[t-1, i]**2 + beta[i] * volatility[t-1, i]**2)\n",
    "    \n",
    "    # Apply volatility to the correlated returns\n",
    "    returns[t] = multi_returns[t] * volatility[t]\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "multi_df = pd.DataFrame(\n",
    "    returns, \n",
    "    columns=['Asset1', 'Asset2'],\n",
    "    index=pd.date_range(start='2020-01-01', periods=n_obs, freq='D')\n",
    ")\n",
    "\n",
    "# Display the first few rows\n",
    "multi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the multivariate returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(multi_df.index, multi_df['Asset1'], label='Asset 1')\n",
    "plt.plot(multi_df.index, multi_df['Asset2'], label='Asset 2')\n",
    "plt.title('Multivariate Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a DCC-GARCH model\n",
    "dcc_model = DCC()\n",
    "dcc_results = dcc_model.fit(multi_df.values)\n",
    "\n",
    "# Display the model summary\n",
    "print(dcc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the estimated conditional correlations\n",
    "correlations = dcc_results.conditional_correlations\n",
    "\n",
    "# Plot the time-varying correlation between the two assets\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(multi_df.index, correlations[:, 0, 1])\n",
    "plt.axhline(y=correlation, color='red', linestyle='--', label='True Correlation')\n",
    "plt.title('DCC-GARCH: Time-Varying Correlation between Assets')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Correlation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Realized Volatility\n",
    "\n",
    "Let's simulate some high-frequency data and compute realized volatility measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate high-frequency price data\n",
    "n_days = 20\n",
    "n_intraday = 100  # 100 observations per day\n",
    "n_total = n_days * n_intraday\n",
    "\n",
    "# Generate a random walk with drift\n",
    "np.random.seed(42)\n",
    "daily_vol = 0.01  # Daily volatility\n",
    "intraday_vol = daily_vol / np.sqrt(n_intraday)  # Intraday volatility\n",
    "drift = 0.0001  # Small drift term\n",
    "\n",
    "# Generate log prices\n",
    "log_returns = np.random.normal(drift, intraday_vol, n_total)\n",
    "log_prices = np.cumsum(log_returns)\n",
    "prices = np.exp(log_prices)\n",
    "\n",
    "# Create a time index (seconds within the trading day)\n",
    "seconds_per_day = 23400  # 6.5 hours = 390 minutes = 23400 seconds\n",
    "seconds_per_obs = seconds_per_day / n_intraday\n",
    "\n",
    "# Create time and price arrays\n",
    "times = np.zeros(n_total)\n",
    "for d in range(n_days):\n",
    "    day_start = d * n_intraday\n",
    "    day_end = (d + 1) * n_intraday\n",
    "    times[day_start:day_end] = np.arange(0, seconds_per_day, seconds_per_obs)\n",
    "\n",
    "# Create a DataFrame with time and price data\n",
    "high_freq_data = pd.DataFrame({\n",
    "    'day': np.repeat(np.arange(n_days), n_intraday),\n",
    "    'time': times,\n",
    "    'price': prices\n",
    "})\n",
    "\n",
    "# Display the first few rows\n",
    "high_freq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the high-frequency price data for the first 3 days\n",
    "plt.figure(figsize=(12, 6))\n",
    "for day in range(3):\n",
    "    day_data = high_freq_data[high_freq_data['day'] == day]\n",
    "    plt.plot(day_data['time'], day_data['price'], label=f'Day {day+1}')\n",
    "    \n",
    "plt.title('High-Frequency Price Data')\n",
    "plt.xlabel('Seconds (within trading day)')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute realized volatility for each day\n",
    "realized_vol = []\n",
    "\n",
    "for day in range(n_days):\n",
    "    # Extract data for this day\n",
    "    day_data = high_freq_data[high_freq_data['day'] == day]\n",
    "    \n",
    "    # Calculate log returns\n",
    "    log_prices = np.log(day_data['price'].values)\n",
    "    log_returns = np.diff(log_prices)\n",
    "    \n",
    "    # Create time and returns arrays for the RealizedVariance estimator\n",
    "    times = day_data['time'].values[1:]  # Skip the first time point\n",
    "    \n",
    "    # Compute realized variance\n",
    "    rv_estimator = RealizedVariance()\n",
    "    rv = rv_estimator.compute(returns=log_returns, times=times)\n",
    "    \n",
    "    realized_vol.append(np.sqrt(rv))\n",
    "\n",
    "# Create a DataFrame with the realized volatility estimates\n",
    "rv_df = pd.DataFrame({\n",
    "    'day': np.arange(n_days),\n",
    "    'realized_volatility': realized_vol\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "rv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the realized volatility estimates\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(rv_df['day'], rv_df['realized_volatility'], width=0.6)\n",
    "plt.axhline(y=daily_vol, color='red', linestyle='--', label='True Daily Volatility')\n",
    "plt.title('Realized Volatility Estimates')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Realized Volatility')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Statistical Distributions\n",
    "\n",
    "The MFE Toolbox provides several statistical distributions commonly used in financial econometrics. Let's explore the Student's t-distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standardized Student's t-distribution with different degrees of freedom\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "t_dist_5 = StudentT(nu=5)  # 5 degrees of freedom\n",
    "t_dist_10 = StudentT(nu=10)  # 10 degrees of freedom\n",
    "t_dist_30 = StudentT(nu=30)  # 30 degrees of freedom\n",
    "\n",
    "# Calculate PDF values\n",
    "pdf_5 = t_dist_5.pdf(x)\n",
    "pdf_10 = t_dist_10.pdf(x)\n",
    "pdf_30 = t_dist_30.pdf(x)\n",
    "\n",
    "# Plot the PDFs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, pdf_5, label='t(5)')\n",
    "plt.plot(x, pdf_10, label='t(10)')\n",
    "plt.plot(x, pdf_30, label='t(30)')\n",
    "plt.plot(x, np.exp(-x**2/2) / np.sqrt(2*np.pi), 'k--', label='Normal')\n",
    "plt.title(\"Student's t-Distribution PDF with Different Degrees of Freedom\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random samples from the t-distribution\n",
    "n_samples = 1000\n",
    "samples_5 = t_dist_5.rvs(size=n_samples)\n",
    "samples_10 = t_dist_10.rvs(size=n_samples)\n",
    "samples_30 = t_dist_30.rvs(size=n_samples)\n",
    "\n",
    "# Plot histograms of the samples\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(samples_5, bins=50, alpha=0.5, label='t(5)')\n",
    "plt.hist(samples_10, bins=50, alpha=0.5, label='t(10)')\n",
    "plt.hist(samples_30, bins=50, alpha=0.5, label='t(30)')\n",
    "plt.title(\"Random Samples from Student's t-Distribution\")\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Matrix Operations\n",
    "\n",
    "The MFE Toolbox provides various matrix operations commonly used in financial econometrics. Let's explore some of these utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a symmetric matrix\n",
    "A = np.array([[1.0, 0.5, 0.3],\n",
    "              [0.5, 2.0, 0.7],\n",
    "              [0.3, 0.7, 3.0]])\n",
    "\n",
    "print(\"Original matrix A:\")\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "# Vectorize the lower triangular part of the matrix (vech operation)\n",
    "v = matrix_ops.vech(A)\n",
    "print(\"vech(A):\")\n",
    "print(v)\n",
    "print()\n",
    "\n",
    "# Reconstruct the matrix from the vectorized form (ivech operation)\n",
    "A_reconstructed = matrix_ops.ivech(v)\n",
    "print(\"ivech(vech(A)):\")\n",
    "print(A_reconstructed)\n",
    "print()\n",
    "\n",
    "# Check if the reconstruction is correct\n",
    "print(\"Reconstruction error:\")\n",
    "print(np.max(np.abs(A - A_reconstructed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Cholesky decomposition\n",
    "L = np.linalg.cholesky(A)\n",
    "print(\"Cholesky factor L:\")\n",
    "print(L)\n",
    "print()\n",
    "\n",
    "# Verify: L @ L.T should equal A\n",
    "print(\"L @ L.T:\")\n",
    "print(L @ L.T)\n",
    "print()\n",
    "\n",
    "# Convert covariance matrix to correlation matrix\n",
    "corr = matrix_ops.cov2corr(A)\n",
    "print(\"Correlation matrix:\")\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: Robust Covariance Estimation\n",
    "\n",
    "Let's demonstrate the robust covariance estimation utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some autocorrelated data\n",
    "n = 500\n",
    "x = np.zeros(n)\n",
    "x[0] = np.random.standard_normal()\n",
    "for t in range(1, n):\n",
    "    x[t] = 0.7 * x[t-1] + np.random.standard_normal()\n",
    "\n",
    "# Create a design matrix with a constant and the lagged variable\n",
    "X = np.column_stack((np.ones(n-1), x[:-1]))\n",
    "y = x[1:]\n",
    "\n",
    "# OLS estimation\n",
    "beta = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "residuals = y - X @ beta\n",
    "\n",
    "# Standard OLS covariance matrix\n",
    "sigma2 = np.sum(residuals**2) / (n - 3)\n",
    "cov_ols = sigma2 * np.linalg.inv(X.T @ X)\n",
    "\n",
    "# Newey-West robust covariance matrix\n",
    "cov_nw = covariance.covnw(X, residuals, lags=5)\n",
    "\n",
    "print(\"OLS Parameter Estimates:\")\n",
    "print(f\"Constant: {beta[0]:.4f}\")\n",
    "print(f\"AR(1) coefficient: {beta[1]:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Standard OLS Standard Errors:\")\n",
    "print(f\"Constant: {np.sqrt(cov_ols[0,0]):.4f}\")\n",
    "print(f\"AR(1) coefficient: {np.sqrt(cov_ols[1,1]):.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Newey-West Robust Standard Errors:\")\n",
    "print(f\"Constant: {np.sqrt(cov_nw[0,0]):.4f}\")\n",
    "print(f\"AR(1) coefficient: {np.sqrt(cov_nw[1,1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has provided an introduction to the MFE Toolbox, demonstrating its core functionality for financial econometrics and time series analysis. We've covered:\n",
    "\n",
    "1. Installation and basic setup\n",
    "2. Working with data using NumPy arrays and Pandas DataFrames\n",
    "3. Univariate volatility modeling with GARCH\n",
    "4. Time series analysis with ARMA\n",
    "5. Bootstrap methods for dependent data\n",
    "6. Multivariate volatility modeling with DCC-GARCH\n",
    "7. Realized volatility estimation\n",
    "8. Statistical distributions\n",
    "9. Matrix operations and robust covariance estimation\n",
    "\n",
    "The MFE Toolbox provides a comprehensive suite of tools for financial econometrics, leveraging the power and flexibility of the Python ecosystem. For more detailed information on specific components, please refer to the documentation and other example notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}