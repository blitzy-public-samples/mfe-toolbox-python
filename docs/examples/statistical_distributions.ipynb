{"cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Distributions in Financial Econometrics\n",
    "\n",
    "This notebook demonstrates the statistical distributions available in the MFE Toolbox for modeling financial returns and their applications in financial econometrics. The MFE Toolbox provides a comprehensive set of distribution classes that extend SciPy's distribution framework with additional features specifically designed for financial time series analysis.\n",
    "\n",
    "## Key Features of MFE Distributions\n",
    "\n",
    "- **Class-based implementation** with inheritance from a common base class\n",
    "- **Type-validated parameters** using Python dataclasses\n",
    "- **Numba-accelerated core functions** for performance-critical operations\n",
    "- **Vectorized operations** supporting NumPy arrays and Pandas Series\n",
    "- **Comprehensive error handling** with descriptive messages\n",
    "- **Integration with SciPy's stats module** where applicable\n",
    "\n",
    "## Available Distributions\n",
    "\n",
    "The MFE Toolbox includes the following distributions:\n",
    "\n",
    "1. **Normal Distribution**: The standard normal (Gaussian) distribution\n",
    "2. **Student's t-Distribution**: The standardized Student's t-distribution for modeling heavy tails\n",
    "3. **Generalized Error Distribution (GED)**: Flexible distribution with adjustable tail thickness\n",
    "4. **Skewed t-Distribution**: Hansen's skewed t-distribution for asymmetric heavy-tailed data\n",
    "\n",
    "Let's start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "# Import MFE Toolbox distributions\n",
    "from mfe.models.distributions import Normal, StudentT, GeneralizedError, SkewedT\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Normal Distribution\n",
    "\n",
    "The normal distribution is the most commonly used distribution in statistics and finance. While financial returns often exhibit non-normal characteristics (heavy tails, skewness), the normal distribution serves as an important baseline.\n",
    "\n",
    "The `Normal` class in the MFE Toolbox provides a standardized interface for working with Gaussian distributions, extending SciPy's implementation with additional features for financial applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Normal distribution instance\n",
    "normal = Normal()\n",
    "\n",
    "# Generate sample data\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# Calculate PDF and CDF values (vectorized operations)\n",
    "pdf_values = normal.pdf(x)\n",
    "cdf_values = normal.cdf(x)\n",
    "\n",
    "# Plot the results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(x, pdf_values, 'b-', linewidth=2)\n",
    "ax1.set_title('Normal Probability Density Function')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('Density')\n",
    "\n",
    "ax2.plot(x, cdf_values, 'r-', linewidth=2)\n",
    "ax2.set_title('Normal Cumulative Distribution Function')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Random Number Generation\n",
    "\n",
    "The `Normal` class provides methods for generating random samples and calculating log-likelihood, which are essential for simulation and parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10,000 random samples\n",
    "np.random.seed(42)  # For reproducibility\n",
    "samples = normal.rvs(size=10000)\n",
    "\n",
    "# Plot histogram of the samples\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(samples, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Overlay the PDF\n",
    "x_plot = np.linspace(-4, 4, 1000)\n",
    "plt.plot(x_plot, normal.pdf(x_plot), 'r-', linewidth=2, label='Normal PDF')\n",
    "\n",
    "plt.title('Histogram of Random Samples from Normal Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate log-likelihood for a data vector\n",
    "data = np.array([0.1, -0.2, 0.3, -0.1, 0.2])\n",
    "log_likelihood = normal.loglikelihood(data)\n",
    "print(f\"Log-likelihood for data {data}: {log_likelihood:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Quantile Function (Value-at-Risk)\n",
    "\n",
    "The quantile function (inverse CDF) is particularly useful in risk management for calculating Value-at-Risk (VaR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles (Value-at-Risk)\n",
    "var_95 = normal.ppf(0.05)  # 5% VaR (95% confidence level)\n",
    "var_99 = normal.ppf(0.01)  # 1% VaR (99% confidence level)\n",
    "\n",
    "print(f\"5% Value-at-Risk (95% confidence): {var_95:.4f}\")\n",
    "print(f\"1% Value-at-Risk (99% confidence): {var_99:.4f}\")\n",
    "\n",
    "# Visualize VaR on the PDF\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, normal.pdf(x), 'b-', linewidth=2)\n",
    "\n",
    "# Shade the area beyond VaR\n",
    "x_tail = np.linspace(-4, var_95, 200)\n",
    "plt.fill_between(x_tail, normal.pdf(x_tail), alpha=0.3, color='red')\n",
    "\n",
    "# Add VaR line\n",
    "plt.axvline(x=var_95, color='red', linestyle='--', linewidth=2, \
",
    "            label=f'5% VaR = {var_95:.4f}')\n",
    "\n",
    "plt.title('Normal Distribution with 5% Value-at-Risk')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Student's t-Distribution\n",
    "\n",
    "Financial returns often exhibit heavy tails, meaning extreme events occur more frequently than would be predicted by a normal distribution. The Student's t-distribution is commonly used to model this behavior.\n",
    "\n",
    "The `StudentT` class in the MFE Toolbox implements the standardized Student's t-distribution with a parameter `nu` (degrees of freedom) that controls the tail thickness. Smaller values of `nu` result in heavier tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StudentT distribution instances with different degrees of freedom\n",
    "t_dist_3 = StudentT(nu=3)  # 3 degrees of freedom (heavy tails)\n",
    "t_dist_5 = StudentT(nu=5)  # 5 degrees of freedom (moderate tails)\n",
    "t_dist_10 = StudentT(nu=10)  # 10 degrees of freedom (lighter tails)\n",
    "normal = Normal()  # For comparison\n",
    "\n",
    "# Generate sample data\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# Calculate PDF values\n",
    "pdf_t3 = t_dist_3.pdf(x)\n",
    "pdf_t5 = t_dist_5.pdf(x)\n",
    "pdf_t10 = t_dist_10.pdf(x)\n",
    "pdf_normal = normal.pdf(x)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, pdf_normal, 'k-', linewidth=2, label='Normal')\n",
    "plt.plot(x, pdf_t3, 'r-', linewidth=2, label='t(3)')\n",
    "plt.plot(x, pdf_t5, 'g-', linewidth=2, label='t(5)')\n",
    "plt.plot(x, pdf_t10, 'b-', linewidth=2, label='t(10)')\n",
    "\n",
    "plt.title('Standardized t-Distribution PDF with Different Degrees of Freedom')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Zoom in on the tails\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, pdf_normal, 'k-', linewidth=2, label='Normal')\n",
    "plt.plot(x, pdf_t3, 'r-', linewidth=2, label='t(3)')\n",
    "plt.plot(x, pdf_t5, 'g-', linewidth=2, label='t(5)')\n",
    "plt.plot(x, pdf_t10, 'b-', linewidth=2, label='t(10)')\n",
    "\n",
    "plt.title('Tail Behavior of t-Distribution (Zoomed)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(-4, -2)  # Focus on the left tail\n",
    "plt.ylim(0, 0.05)  # Adjust y-axis to see the tail differences\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Parameter Validation with Dataclasses\n",
    "\n",
    "The `StudentT` class uses Python's dataclass for parameter validation, ensuring that the degrees of freedom parameter satisfies the necessary constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate parameter validation\n",
    "try:\n",
    "    invalid_t = StudentT(nu=1.5)  # nu must be > 2 for finite variance\n",
    "except ValueError as e:\n",
    "    print(f\"Validation error: {e}\")\n",
    "\n",
    "# Examine the dataclass structure\n",
    "print(\"\\nStudent's t-distribution parameters:\")\n",
    "print(f\"t_dist_5.nu = {t_dist_5.nu}\")\n",
    "\n",
    "# Generate random samples\n",
    "np.random.seed(42)  # For reproducibility\n",
    "samples_normal = normal.rvs(size=1000)\n",
    "samples_t5 = t_dist_5.rvs(size=1000)\n",
    "\n",
    "# Compare histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(samples_normal, bins=50, density=True, alpha=0.5, color='blue', \
",
    "         edgecolor='black', label='Normal Samples')\n",
    "plt.hist(samples_t5, bins=50, density=True, alpha=0.5, color='red', \
",
    "         edgecolor='black', label='t(5) Samples')\n",
    "\n",
    "plt.title('Comparison of Random Samples: Normal vs. t(5)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Value-at-Risk Comparison\n",
    "\n",
    "Let's compare the Value-at-Risk (VaR) estimates from the normal distribution and the t-distribution. This comparison illustrates why using appropriate distributions is crucial for accurate risk assessment in finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VaR for different distributions\n",
    "var_95_normal = normal.ppf(0.05)  # 5% VaR with normal distribution\n",
    "var_95_t3 = t_dist_3.ppf(0.05)    # 5% VaR with t(3) distribution\n",
    "var_95_t5 = t_dist_5.ppf(0.05)    # 5% VaR with t(5) distribution\n",
    "var_95_t10 = t_dist_10.ppf(0.05)  # 5% VaR with t(10) distribution\n",
    "\n",
    "print(f\"5% VaR with Normal distribution: {var_95_normal:.4f}\")\n",
    "print(f\"5% VaR with t(3) distribution:   {var_95_t3:.4f}\")\n",
    "print(f\"5% VaR with t(5) distribution:   {var_95_t5:.4f}\")\n",
    "print(f\"5% VaR with t(10) distribution:  {var_95_t10:.4f}\")\n",
    "\n",
    "# Visualize VaR comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot PDFs\n",
    "plt.plot(x, pdf_normal, 'k-', linewidth=2, label='Normal')\n",
    "plt.plot(x, pdf_t3, 'r-', linewidth=2, label='t(3)')\n",
    "plt.plot(x, pdf_t5, 'g-', linewidth=2, label='t(5)')\n",
    "\n",
    "# Add VaR lines\n",
    "plt.axvline(x=var_95_normal, color='k', linestyle='--', linewidth=2, \
",
    "            label=f'Normal VaR: {var_95_normal:.4f}')\n",
    "plt.axvline(x=var_95_t3, color='r', linestyle='--', linewidth=2, \
",
    "            label=f't(3) VaR: {var_95_t3:.4f}')\n",
    "plt.axvline(x=var_95_t5, color='g', linestyle='--', linewidth=2, \
",
    "            label=f't(5) VaR: {var_95_t5:.4f}')\n",
    "\n",
    "plt.title('Value-at-Risk Comparison: Normal vs. t-Distribution')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(-4, 0)  # Focus on the left tail where VaR is located\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generalized Error Distribution (GED)\n",
    "\n",
    "The Generalized Error Distribution (GED) provides a flexible family of distributions with adjustable tail thickness. The parameter `nu` controls the shape of the distribution:\n",
    "\n",
    "- `nu = 1`: Laplace distribution (sharper peak, heavier tails than normal)\n",
    "- `nu = 2`: Normal distribution\n",
    "- `nu > 2`: Thinner tails than normal\n",
    "\n",
    "The `GeneralizedError` class in the MFE Toolbox implements this distribution with Numba-accelerated core functions for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GED instances with different shape parameters\n",
    "ged_1 = GeneralizedError(nu=1.0)  # Laplace distribution\n",
    "ged_2 = GeneralizedError(nu=2.0)  # Normal distribution\n",
    "ged_5 = GeneralizedError(nu=5.0)  # Thinner tails than normal\n",
    "\n",
    "# Generate sample data\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# Calculate PDF values\n",
    "pdf_ged1 = ged_1.pdf(x)\n",
    "pdf_ged2 = ged_2.pdf(x)\n",
    "pdf_ged5 = ged_5.pdf(x)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, pdf_ged1, 'r-', linewidth=2, label='GED(1.0) - Laplace')\n",
    "plt.plot(x, pdf_ged2, 'g-', linewidth=2, label='GED(2.0) - Normal')\n",
    "plt.plot(x, pdf_ged5, 'b-', linewidth=2, label='GED(5.0)')\n",
    "\n",
    "plt.title('Generalized Error Distribution PDF with Different Shape Parameters')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Numba-Accelerated Performance\n",
    "\n",
    "The `GeneralizedError` class uses Numba's JIT compilation to accelerate performance-critical functions. Let's compare the performance of the PDF calculation with and without Numba acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate large data array\n",
    "np.random.seed(42)  # For reproducibility\n",
    "large_data = np.random.randn(100000)\n",
    "\n",
    "# Define a pure Python implementation of the GED PDF for comparison\n",
    "def ged_pdf_python(x, nu):\n",
    "    \"\"\"Pure Python implementation of GED PDF without Numba.\"\"\"\n",
    "    lambda_val = np.sqrt(2**(-2/nu) * np.exp(np.log(np.exp(np.log(3) + np.log(nu)) / np.exp(np.log(2) + np.log(nu))) + np.log(np.exp(np.log(1) + np.log(nu)) / np.exp(np.log(2) + np.log(nu)))))\n",
    "    c = nu / (2 * lambda_val * np.exp(np.log(np.exp(np.log(1) + np.log(nu)) / np.exp(np.log(2) + np.log(nu)))))\n",
    "    \n",
    "    result = np.zeros_like(x, dtype=float)\n",
    "    for i in range(len(x)):\n",
    "        result[i] = c * np.exp(-0.5 * np.abs(x[i] / lambda_val)**nu)\n",
    "    return result\n",
    "\n",
    "# Time the Numba-accelerated implementation\n",
    "start_time = time.time()\n",
    "pdf_values_numba = ged_2.pdf(large_data)\n",
    "numba_time = time.time() - start_time\n",
    "\n",
    "# Time the pure Python implementation\n",
    "start_time = time.time()\n",
    "pdf_values_python = ged_pdf_python(large_data, 2.0)\n",
    "python_time = time.time() - start_time\n",
    "\n",
    "print(f\"Time to compute 100,000 PDF values with Numba: {numba_time*1000:.2f} ms\")\n",
    "print(f\"Time to compute 100,000 PDF values with pure Python: {python_time*1000:.2f} ms\")\n",
    "print(f\"Speedup factor: {python_time/numba_time:.1f}x\")\n",
    "\n",
    "# Verify that both implementations give the same results\n",
    "max_diff = np.max(np.abs(pdf_values_numba - pdf_values_python))\n",
    "print(f\"Maximum absolute difference between implementations: {max_diff:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Number Generation and Quantiles\n",
    "\n",
    "Let's generate random samples from the GED and calculate quantiles for risk management applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random samples\n",
    "np.random.seed(42)  # For reproducibility\n",
    "samples_ged1 = ged_1.rvs(size=1000)  # Laplace\n",
    "samples_ged2 = ged_2.rvs(size=1000)  # Normal\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(samples_ged1, bins=50, density=True, alpha=0.5, color='red', \
",
    "         edgecolor='black', label='GED(1.0) - Laplace')\n",
    "plt.hist(samples_ged2, bins=50, density=True, alpha=0.5, color='blue', \
",
    "         edgecolor='black', label='GED(2.0) - Normal')\n",
    "\n",
    "# Overlay PDFs\n",
    "x_plot = np.linspace(-4, 4, 1000)\n",
    "plt.plot(x_plot, ged_1.pdf(x_plot), 'r-', linewidth=2)\n",
    "plt.plot(x_plot, ged_2.pdf(x_plot), 'b-', linewidth=2)\n",
    "\n",
    "plt.title('Random Samples from Generalized Error Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate quantiles (Value-at-Risk)\n",
    "var_95_ged1 = ged_1.ppf(0.05)  # 5% VaR with Laplace distribution\n",
    "var_95_ged2 = ged_2.ppf(0.05)  # 5% VaR with Normal distribution\n",
    "var_95_ged5 = ged_5.ppf(0.05)  # 5% VaR with GED(5) distribution\n",
    "\n",
    "print(f\"5% VaR with GED(1.0) - Laplace: {var_95_ged1:.4f}\")\n",
    "print(f\"5% VaR with GED(2.0) - Normal:  {var_95_ged2:.4f}\")\n",
    "print(f\"5% VaR with GED(5.0):           {var_95_ged5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Skewed t-Distribution\n",
    "\n",
    "Financial returns often exhibit not only heavy tails but also asymmetry (skewness). Hansen's skewed t-distribution extends the Student's t-distribution to account for this asymmetry.\n",
    "\n",
    "The `SkewedT` class in the MFE Toolbox implements this distribution with two parameters:\n",
    "- `nu`: Controls tail thickness (degrees of freedom)\n",
    "- `lambda_`: Controls asymmetry (skewness parameter in [-1, 1])\n",
    "\n",
    "When `lambda_ = 0`, the distribution reduces to the standard Student's t-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SkewedT instances with different parameters\n",
    "skewt_sym = SkewedT(nu=5, lambda_=0.0)   # Symmetric (standard t)\n",
    "skewt_neg = SkewedT(nu=5, lambda_=-0.5)  # Negative skew\n",
    "skewt_pos = SkewedT(nu=5, lambda_=0.5)   # Positive skew\n",
    "\n",
    "# Generate sample data\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# Calculate PDF values\n",
    "pdf_sym = skewt_sym.pdf(x)\n",
    "pdf_neg = skewt_neg.pdf(x)\n",
    "pdf_pos = skewt_pos.pdf(x)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, pdf_sym, 'k-', linewidth=2, label='Symmetric (λ=0)')\n",
    "plt.plot(x, pdf_neg, 'r-', linewidth=2, label='Negative Skew (λ=-0.5)')\n",
    "plt.plot(x, pdf_pos, 'g-', linewidth=2, label='Positive Skew (λ=0.5)')\n",
    "\n",
    "plt.title(\"Hansen's Skewed t-Distribution PDF\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Parameter Validation and Type Safety\n",
    "\n",
    "The `SkewedT` class uses dataclasses for parameter validation and provides comprehensive error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate parameter validation\n",
    "try:\n",
    "    invalid_skewt = SkewedT(nu=1.5, lambda_=0.0)  # nu must be > 2\n",
    "except ValueError as e:\n",
    "    print(f\"Validation error: {e}\")\n",
    "\n",
    "try:\n",
    "    invalid_skewt = SkewedT(nu=5, lambda_=1.5)  # lambda must be in [-1, 1]\n",
    "except ValueError as e:\n",
    "    print(f\"Validation error: {e}\")\n",
    "\n",
    "# Examine the dataclass structure\n",
    "print(\"\\nSkewed t-distribution parameters:\")\n",
    "print(f\"skewt_pos.nu = {skewt_pos.nu}\")\n",
    "print(f\"skewt_pos.lambda_ = {skewt_pos.lambda_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random Sampling and Value-at-Risk\n",
    "\n",
    "Let's generate random samples from the skewed t-distribution and calculate Value-at-Risk (VaR) for different skewness parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random samples\n",
    "np.random.seed(42)  # For reproducibility\n",
    "samples_sym = skewt_sym.rvs(size=1000)  # Symmetric\n",
    "samples_neg = skewt_neg.rvs(size=1000)  # Negative skew\n",
    "samples_pos = skewt_pos.rvs(size=1000)  # Positive skew\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(samples_sym, bins=50, density=True, alpha=0.5, color='blue', \
",
    "         edgecolor='black', label='Symmetric (λ=0)')\n",
    "plt.hist(samples_neg, bins=50, density=True, alpha=0.5, color='red', \
",
    "         edgecolor='black', label='Negative Skew (λ=-0.5)')\n",
    "plt.hist(samples_pos, bins=50, density=True, alpha=0.5, color='green', \
",
    "         edgecolor='black', label='Positive Skew (λ=0.5)')\n",
    "\n",
    "plt.title(\"Random Samples from Hansen's Skewed t-Distribution\")\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate quantiles (Value-at-Risk)\n",
    "var_95_sym = skewt_sym.ppf(0.05)  # 5% VaR with symmetric t\n",
    "var_95_neg = skewt_neg.ppf(0.05)  # 5% VaR with negative skew\n",
    "var_95_pos = skewt_pos.ppf(0.05)  # 5% VaR with positive skew\n",
    "\n",
    "print(f\"5% VaR with Symmetric t (λ=0):      {var_95_sym:.4f}\")\n",
    "print(f\"5% VaR with Negative Skew (λ=-0.5): {var_95_neg:.4f}\")\n",
    "print(f\"5% VaR with Positive Skew (λ=0.5):  {var_95_pos:.4f}\")\n",
    "\n",
    "# Visualize VaR comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot PDFs\n",
    "plt.plot(x, pdf_sym, 'k-', linewidth=2, label='Symmetric (λ=0)')\n",
    "plt.plot(x, pdf_neg, 'r-', linewidth=2, label='Negative Skew (λ=-0.5)')\n",
    "plt.plot(x, pdf_pos, 'g-', linewidth=2, label='Positive Skew (λ=0.5)')\n",
    "\n",
    "# Add VaR lines\n",
    "plt.axvline(x=var_95_sym, color='k', linestyle='--', linewidth=2, \
",
    "            label=f'Symmetric VaR: {var_95_sym:.4f}')\n",
    "plt.axvline(x=var_95_neg, color='r', linestyle='--', linewidth=2, \
",
    "            label=f'Negative Skew VaR: {var_95_neg:.4f}')\n",
    "plt.axvline(x=var_95_pos, color='g', linestyle='--', linewidth=2, \
",
    "            label=f'Positive Skew VaR: {var_95_pos:.4f}')\n",
    "\n",
    "plt.title('Value-at-Risk Comparison: Skewed t-Distribution')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(-4, 0)  # Focus on the left tail where VaR is located\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Application: Fitting Distributions to Financial Returns\n",
    "\n",
    "Now let's apply these distributions to real financial data. We'll use daily returns from a stock index and fit different distributions to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic financial returns data (for demonstration)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_samples = 1000\n",
    "# Generate returns from a skewed t-distribution to simulate realistic financial returns\n",
    "true_dist = SkewedT(nu=4, lambda_=-0.2)  # Slightly negative skew, heavy tails\n",
    "returns = true_dist.rvs(size=n_samples)\n",
    "\n",
    "# Create a pandas Series with dates\n",
    "dates = pd.date_range(start='2020-01-01', periods=n_samples, freq='B')\n",
    "returns_series = pd.Series(returns, index=dates, name='Returns')\n",
    "\n",
    "# Plot the returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(returns_series.index, returns_series, 'b-', linewidth=1)\n",
    "plt.title('Simulated Daily Stock Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Return')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot the histogram of returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(returns_series, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Daily Returns')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "mean = returns_series.mean()\n",
    "std = returns_series.std()\n",
    "skewness = returns_series.skew()\n",
    "kurtosis = returns_series.kurtosis()  # Excess kurtosis\n",
    "\n",
    "print(f\"Mean:             {mean:.6f}\")\n",
    "print(f\"Standard Deviation: {std:.6f}\")\n",
    "print(f\"Skewness:         {skewness:.6f}\")\n",
    "print(f\"Excess Kurtosis:  {kurtosis:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Maximum Likelihood Estimation\n",
    "\n",
    "Let's fit different distributions to the returns data using maximum likelihood estimation (MLE) and compare their goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the returns for fitting\n",
    "standardized_returns = (returns_series - returns_series.mean()) / returns_series.std()\n",
    "\n",
    "# Fit Normal distribution\n",
    "normal = Normal()\n",
    "ll_normal = normal.loglikelihood(standardized_returns.values)\n",
    "\n",
    "# Fit Student's t-distribution (search for optimal nu)\n",
    "nu_values = np.linspace(2.1, 10, 50)\n",
    "ll_t_values = []\n",
    "\n",
    "for nu in nu_values:\n",
    "    t_dist = StudentT(nu=nu)\n",
    "    ll_t_values.append(t_dist.loglikelihood(standardized_returns.values))\n",
    "\n",
    "best_nu_idx = np.argmax(ll_t_values)\n",
    "best_nu = nu_values[best_nu_idx]\n",
    "best_t_dist = StudentT(nu=best_nu)\n",
    "ll_t_best = ll_t_values[best_nu_idx]\n",
    "\n",
    "# Fit Skewed t-distribution (grid search for optimal nu and lambda)\n",
    "nu_grid = np.linspace(2.1, 10, 20)\n",
    "lambda_grid = np.linspace(-0.9, 0.9, 20)\n",
    "ll_skewt_grid = np.zeros((len(nu_grid), len(lambda_grid)))\n",
    "\n",
    "for i, nu in enumerate(nu_grid):\n",
    "    for j, lambda_ in enumerate(lambda_grid):\n",
    "        skewt = SkewedT(nu=nu, lambda_=lambda_)\n",
    "        ll_skewt_grid[i, j] = skewt.loglikelihood(standardized_returns.values)\n",
    "\n",
    "# Find the best parameters\n",
    "best_idx = np.unravel_index(np.argmax(ll_skewt_grid), ll_skewt_grid.shape)\n",
    "best_nu_skewt = nu_grid[best_idx[0]]\n",
    "best_lambda = lambda_grid[best_idx[1]]\n",
    "best_skewt = SkewedT(nu=best_nu_skewt, lambda_=best_lambda)\n",
    "ll_skewt_best = ll_skewt_grid[best_idx]\n",
    "\n",
    "# Print results\n",
    "print(\"Maximum Likelihood Estimation Results:\")\n",
    "print(f\"Normal distribution:\")\n",
    "print(f\"  Log-likelihood: {ll_normal:.4f}\")\n",
    "print(f\"\\nStudent's t-distribution:\")\n",
    "print(f\"  Best nu: {best_nu:.4f}\")\n",
    "print(f\"  Log-likelihood: {ll_t_best:.4f}\")\n",
    "print(f\"\\nSkewed t-distribution:\")\n",
    "print(f\"  Best nu: {best_nu_skewt:.4f}\")\n",
    "print(f\"  Best lambda: {best_lambda:.4f}\")\n",
    "print(f\"  Log-likelihood: {ll_skewt_best:.4f}\")\n",
    "\n",
    "# Calculate AIC and BIC\n",
    "n = len(standardized_returns)\n",
    "aic_normal = -2 * ll_normal + 2 * 0  # Normal has 0 free parameters (standardized)\n",
    "aic_t = -2 * ll_t_best + 2 * 1       # t has 1 free parameter (nu)\n",
    "aic_skewt = -2 * ll_skewt_best + 2 * 2  # Skewed t has 2 free parameters (nu, lambda)\n",
    "\n",
    "bic_normal = -2 * ll_normal + 0 * np.log(n)\n",
    "bic_t = -2 * ll_t_best + 1 * np.log(n)\n",
    "bic_skewt = -2 * ll_skewt_best + 2 * np.log(n)\n",
    "\n",
    "print(\"\\nModel Selection Criteria:\")\n",
    "print(f\"AIC - Normal: {aic_normal:.4f}, t: {aic_t:.4f}, Skewed t: {aic_skewt:.4f}\")\n",
    "print(f\"BIC - Normal: {bic_normal:.4f}, t: {bic_t:.4f}, Skewed t: {bic_skewt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Visualizing the Fitted Distributions\n",
    "\n",
    "Let's visualize how well each distribution fits the empirical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points for plotting the PDFs\n",
    "x_plot = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# Calculate PDF values\n",
    "pdf_normal = normal.pdf(x_plot)\n",
    "pdf_t = best_t_dist.pdf(x_plot)\n",
    "pdf_skewt = best_skewt.pdf(x_plot)\n",
    "\n",
    "# Plot histogram and fitted distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(standardized_returns, bins=50, density=True, alpha=0.5, color='gray', \
",
    "         edgecolor='black', label='Empirical Data')\n",
    "\n",
    "plt.plot(x_plot, pdf_normal, 'b-', linewidth=2, label='Normal')\n",
    "plt.plot(x_plot, pdf_t, 'r-', linewidth=2, \
",
    "         label=f\"Student's t (ν={best_nu:.2f})\")\n",
    "plt.plot(x_plot, pdf_skewt, 'g-', linewidth=2, \
",
    "         label=f\"Skewed t (ν={best_nu_skewt:.2f}, λ={best_lambda:.2f})\")\n",
    "\n",
    "plt.title('Fitted Distributions to Standardized Returns')\n",
    "plt.xlabel('Standardized Return')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Focus on the tails\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Left tail\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(standardized_returns, bins=50, density=True, alpha=0.5, color='gray', \
",
    "         edgecolor='black', label='Empirical Data')\n",
    "plt.plot(x_plot, pdf_normal, 'b-', linewidth=2, label='Normal')\n",
    "plt.plot(x_plot, pdf_t, 'r-', linewidth=2, \
",
    "         label=f\"Student's t (ν={best_nu:.2f})\")\n",
    "plt.plot(x_plot, pdf_skewt, 'g-', linewidth=2, \
",
    "         label=f\"Skewed t (ν={best_nu_skewt:.2f}, λ={best_lambda:.2f})\")\n",
    "plt.title('Left Tail Fit')\n",
    "plt.xlabel('Standardized Return')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(-4, -1.5)  # Focus on the left tail\n",
    "plt.ylim(0, 0.1)    # Adjust y-axis to see the tail differences\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Right tail\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(standardized_returns, bins=50, density=True, alpha=0.5, color='gray', \
",
    "         edgecolor='black', label='Empirical Data')\n",
    "plt.plot(x_plot, pdf_normal, 'b-', linewidth=2, label='Normal')\n",
    "plt.plot(x_plot, pdf_t, 'r-', linewidth=2, \
",
    "         label=f\"Student's t (ν={best_nu:.2f})\")\n",
    "plt.plot(x_plot, pdf_skewt, 'g-', linewidth=2, \
",
    "         label=f\"Skewed t (ν={best_nu_skewt:.2f}, λ={best_lambda:.2f})\")\n",
    "plt.title('Right Tail Fit')\n",
    "plt.xlabel('Standardized Return')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(1.5, 4)    # Focus on the right tail\n",
    "plt.ylim(0, 0.1)    # Adjust y-axis to see the tail differences\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Value-at-Risk and Expected Shortfall Estimation\n",
    "\n",
    "Let's calculate Value-at-Risk (VaR) and Expected Shortfall (ES) using the fitted distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VaR at different confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99]\n",
    "alpha_levels = [1 - cl for cl in confidence_levels]\n",
    "\n",
    "# Calculate VaR for each distribution\n",
    "var_normal = [normal.ppf(alpha) for alpha in alpha_levels]\n",
    "var_t = [best_t_dist.ppf(alpha) for alpha in alpha_levels]\n",
    "var_skewt = [best_skewt.ppf(alpha) for alpha in alpha_levels]\n",
    "\n",
    "# Calculate empirical VaR\n",
    "var_empirical = [np.percentile(standardized_returns, 100 * alpha) for alpha in alpha_levels]\n",
    "\n",
    "# Calculate Expected Shortfall (ES) for each distribution\n",
    "# For normal distribution, ES has a closed form\n",
    "es_normal = [normal.pdf(var_normal[i]) / alpha_levels[i] for i in range(len(alpha_levels))]\n",
    "\n",
    "# For t and skewed t, we'll use numerical integration\n",
    "def expected_shortfall(dist, var_value, alpha):\n",
    "    \"\"\"Calculate Expected Shortfall using numerical integration.\"\"\"\n",
    "    x_grid = np.linspace(-10, var_value, 1000)  # Integration range\n",
    "    pdf_values = dist.pdf(x_grid)\n",
    "    # ES = (1/alpha) * ∫_{-∞}^{VaR} x * f(x) dx\n",
    "    integrand = x_grid * pdf_values\n",
    "    return np.trapz(integrand, x_grid) / alpha\n",
    "\n",
    "es_t = [expected_shortfall(best_t_dist, var_t[i], alpha_levels[i]) \n",
    "        for i in range(len(alpha_levels))]\n",
    "es_skewt = [expected_shortfall(best_skewt, var_skewt[i], alpha_levels[i]) \n",
    "           for i in range(len(alpha_levels))]\n",
    "\n",
    "# Calculate empirical ES\n",
    "def empirical_es(returns, alpha):\n",
    "    \"\"\"Calculate empirical Expected Shortfall.\"\"\"\n",
    "    var_value = np.percentile(returns, 100 * alpha)\n",
    "    tail_returns = returns[returns <= var_value]\n",
    "    return tail_returns.mean()\n",
    "\n",
    "es_empirical = [empirical_es(standardized_returns, alpha_levels[i]) \n",
    "               for i in range(len(alpha_levels))]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results = pd.DataFrame({\n",
    "    'Confidence Level': confidence_levels,\n",
    "    'VaR (Normal)': var_normal,\n",
    "    'VaR (t)': var_t,\n",
    "    'VaR (Skewed t)': var_skewt,\n",
    "    'VaR (Empirical)': var_empirical,\n",
    "    'ES (Normal)': es_normal,\n",
    "    'ES (t)': es_t,\n",
    "    'ES (Skewed t)': es_skewt,\n",
    "    'ES (Empirical)': es_empirical\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(\"Value-at-Risk (VaR) and Expected Shortfall (ES) Estimates:\")\n",
    "pd.set_option('display.precision', 4)\n",
    "display(results)\n",
    "\n",
    "# Visualize VaR and ES\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(standardized_returns, bins=50, density=True, alpha=0.5, color='gray', \
",
    "         edgecolor='black', label='Empirical Data')\n",
    "\n",
    "# Plot PDF of the best-fitting distribution (skewed t)\n",
    "plt.plot(x_plot, pdf_skewt, 'g-', linewidth=2, \
",
    "         label=f\"Skewed t (ν={best_nu_skewt:.2f}, λ={best_lambda:.2f})\")\n",
    "\n",
    "# Add VaR and ES lines for 95% confidence\n",
    "idx = 1  # 95% confidence level\n",
    "plt.axvline(x=var_skewt[idx], color='r', linestyle='--', linewidth=2, \
",
    "            label=f'95% VaR (Skewed t): {var_skewt[idx]:.4f}')\n",
    "plt.axvline(x=es_skewt[idx], color='b', linestyle='--', linewidth=2, \
",
    "            label=f'95% ES (Skewed t): {es_skewt[idx]:.4f}')\n",
    "\n",
    "# Shade the area beyond VaR\n",
    "x_tail = np.linspace(-4, var_skewt[idx], 200)\n",
    "plt.fill_between(x_tail, best_skewt.pdf(x_tail), alpha=0.3, color='red')\n",
    "\n",
    "plt.title('Value-at-Risk and Expected Shortfall with Skewed t-Distribution')\n",
    "plt.xlabel('Standardized Return')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Integration with Volatility Models\n",
    "\n",
    "The distribution classes in the MFE Toolbox are designed to integrate seamlessly with volatility models. Let's demonstrate how to use the Student's t-distribution with a GARCH model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GARCH model\n",
    "from mfe.models.univariate import GARCH\n",
    "\n",
    "# Create a GARCH model with Student's t errors\n",
    "t_dist = StudentT(nu=5)  # Initial degrees of freedom\n",
    "garch_model = GARCH(p=1, q=1, distribution=t_dist)\n",
    "\n",
    "# Fit the model to the returns data\n",
    "result = garch_model.fit(returns_series.values)\n",
    "\n",
    "# Access the estimated parameters\n",
    "omega = result.parameters.omega\n",
    "alpha = result.parameters.alpha\n",
    "beta = result.parameters.beta\n",
    "nu = result.distribution_params.nu\n",
    "\n",
    "print(\"GARCH(1,1) Model with Student's t Errors:\")\n",
    "print(f\"omega: {omega:.6f}\")\n",
    "print(f\"alpha: {alpha:.6f}\")\n",
    "print(f\"beta:  {beta:.6f}\")\n",
    "print(f\"nu:    {nu:.6f}\")\n",
    "print(f\"Log-likelihood: {result.log_likelihood:.4f}\")\n",
    "\n",
    "# Plot the conditional volatility\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Returns and conditional volatility\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(returns_series.index, returns_series, 'b-', linewidth=1, alpha=0.7)\n",
    "plt.title('Returns and Conditional Volatility')\n",
    "plt.ylabel('Return')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(returns_series.index, result.conditional_volatility, 'r-', linewidth=1.5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Conditional Volatility')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate forecasts\n",
    "horizon = 10  # 10-day forecast\n",
    "forecasts = garch_model.forecast(horizon=horizon, method='simulation', n_sims=1000)\n",
    "\n",
    "# Calculate VaR using the fitted distribution\n",
    "var_95 = forecasts.volatility[0] * t_dist.ppf(0.05)\n",
    "var_99 = forecasts.volatility[0] * t_dist.ppf(0.01)\n",
    "\n",
    "print(f\"\\nForecasting Results:\")\n",
    "print(f\"1-day ahead volatility forecast: {forecasts.volatility[0]:.6f}\")\n",
    "print(f\"1-day ahead 5% VaR: {var_95:.6f}\")\n",
    "print(f\"1-day ahead 1% VaR: {var_99:.6f}\")\n",
    "\n",
    "# Plot volatility forecasts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, horizon+1), forecasts.volatility, 'ro-', linewidth=2)\n",
    "plt.title(f'{horizon}-Day Volatility Forecast')\n",
    "plt.xlabel('Horizon (days)')\n",
    "plt.ylabel('Conditional Volatility')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Usage: Composite Likelihood\n",
    "\n",
    "For multivariate models, the MFE Toolbox provides a `CompositeLikelihood` class that combines multiple univariate distributions. This is particularly useful for multivariate volatility models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CompositeLikelihood\n",
    "from mfe.models.distributions import CompositeLikelihood\n",
    "\n",
    "# Create individual distributions for a 3-asset portfolio\n",
    "t_dist1 = StudentT(nu=4)    # Asset 1: Heavy tails\n",
    "t_dist2 = StudentT(nu=6)    # Asset 2: Moderate tails\n",
    "skewt_dist = SkewedT(nu=5, lambda_=-0.3)  # Asset 3: Skewed heavy tails\n",
    "\n",
    "# Create a composite likelihood with three distributions\n",
    "composite = CompositeLikelihood([t_dist1, t_dist2, skewt_dist])\n",
    "\n",
    "# Generate multivariate data (3 assets, 5 observations)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "data = np.random.randn(5, 3)  # 5 observations, 3 assets\n",
    "\n",
    "# Calculate the composite log-likelihood\n",
    "log_likelihood = composite.loglikelihood(data)\n",
    "print(f\"Composite log-likelihood: {log_likelihood:.4f}\")\n",
    "\n",
    "# Generate random samples from the composite distribution\n",
    "samples = composite.rvs(size=1000)  # 1000 observations, 3 assets\n",
    "\n",
    "# Plot the samples\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(samples[:, 0], bins=50, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title(f\"Asset 1: Student's t (ν=4)\")\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(samples[:, 1], bins=50, density=True, alpha=0.7, color='green', edgecolor='black')\n",
    "plt.title(f\"Asset 2: Student's t (ν=6)\")\n",
    "plt.xlabel('Return')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(samples[:, 2], bins=50, density=True, alpha=0.7, color='red', edgecolor='black')\n",
    "plt.title(f\"Asset 3: Skewed t (ν=5, λ=-0.3)\")\n",
    "plt.xlabel('Return')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Asynchronous Processing for Large Datasets\n",
    "\n",
    "For computationally intensive operations on large datasets, the distribution classes support asynchronous processing using Python's async/await pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def calculate_large_loglikelihood():\n",
    "    \"\"\"Calculate log-likelihood for a large dataset asynchronously.\"\"\"\n",
    "    # Create a StudentT distribution\n",
    "    t_dist = StudentT(nu=5)\n",
    "    \n",
    "    # Generate large data array\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    large_data = np.random.randn(1000000)\n",
    "    \n",
    "    print(\"Starting asynchronous log-likelihood calculation...\")\n",
    "    \n",
    "    # Calculate log-likelihood asynchronously\n",
    "    start_time = time.time()\n",
    "    result = await t_dist.loglikelihood_async(large_data)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Asynchronous calculation completed in {elapsed_time:.2f} seconds\")\n",
    "    return result\n",
    "\n",
    "# Run the asynchronous function\n",
    "log_likelihood = asyncio.run(calculate_large_loglikelihood())\n",
    "print(f\"Log-likelihood for 1,000,000 observations: {log_likelihood:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Custom Distribution Parameters with Dataclasses\n",
    "\n",
    "The distribution classes use Python's dataclasses for parameter management, allowing for custom parameter validation and type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class CustomStudentTParams:\n",
    "    nu: float\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.nu <= 2:\n",
    "            raise ValueError(\"Degrees of freedom must be > 2 for finite variance\")\n",
    "        if self.nu > 100:\n",
    "            raise ValueError(\"Degrees of freedom too large, consider using Normal distribution\")\n",
    "\n",
    "# Create a StudentT distribution with custom parameters\n",
    "try:\n",
    "    params = CustomStudentTParams(nu=5)\n",
    "    t_dist = StudentT(params=params)\n",
    "    print(f\"Successfully created StudentT with nu={t_dist.nu}\")\n",
    "    \n",
    "    # Try with invalid parameters\n",
    "    invalid_params = CustomStudentTParams(nu=150)  # Should raise ValueError\n",
    "except ValueError as e:\n",
    "    print(f\"Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook has demonstrated the statistical distributions available in the MFE Toolbox and their applications in financial econometrics. Key takeaways include:\n",
    "\n",
    "1. **Class-based implementation**: The MFE Toolbox provides a consistent object-oriented interface for working with distributions, extending SciPy's distribution framework with additional features for financial applications.\n",
    "\n",
    "2. **Type-validated parameters**: Python's dataclasses are used for parameter validation, ensuring that distribution parameters satisfy necessary constraints and providing clear error messages when they don't.\n",
    "\n",
    "3. **Numba-accelerated performance**: Performance-critical functions are accelerated with Numba's JIT compilation, providing significant speedups for large datasets.\n",
    "\n",
    "4. **Integration with volatility models**: The distribution classes are designed to work seamlessly with volatility models for parameter estimation, simulation, and forecasting.\n",
    "\n",
    "5. **Asynchronous processing**: Support for Python's async/await pattern enables non-blocking execution of computationally intensive operations.\n",
    "\n",
    "6. **Risk management applications**: The distributions provide essential tools for Value-at-Risk (VaR) and Expected Shortfall (ES) calculations, with the ability to model heavy tails and skewness commonly observed in financial returns.\n",
    "\n",
    "The MFE Toolbox's distribution classes provide a powerful foundation for financial econometrics, enabling accurate modeling of financial returns and robust risk assessment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}